{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "859125df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "num subjects: 180 20\n",
      "num test edf: 135\n",
      "num train edf: 2163\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "\n",
    "files = []\n",
    "for file in glob.glob(\"/Users/mohamedr/projects/epilespy_connectivity/isip.piconepress.com/projects/tuh_eeg/downloads/tuh_eeg_epilepsy/v2.0.0/*/*/\"):\n",
    "    files.append(file)\n",
    "print(len(files))\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_files, test_files = train_test_split(files, test_size=0.1, random_state=2025)\n",
    "print(\"num subjects:\", len(train_files), len(test_files))\n",
    "\n",
    "files = []\n",
    "for folder in test_files:\n",
    "    for file in glob.glob(folder+\"/*/*/*.edf\"):\n",
    "        files.append(file)\n",
    "print(\"num test edf:\",  len(files))\n",
    "test_files = files\n",
    "\n",
    "files = []\n",
    "for folder in train_files:\n",
    "    for file in glob.glob(folder+\"/*/*/*.edf\"):\n",
    "        files.append(file)\n",
    "print(\"num train edf:\", len(files))\n",
    "train_files = files\n",
    "\n",
    "np.random.shuffle(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41099f51-7b40-4839-a5e4-20a4bd24bedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coh\n",
      "make features\n",
      "read_data\n",
      "Gen features\n",
      "calculating connectivity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1871/1871 [1:16:54<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen features\n",
      "calculating connectivity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [05:05<00:00,  2.52s/it]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TUH Epilipsy Dataset\n",
    "\"\"\"\n",
    "\n",
    "import glob, os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#from src.model import EEGModel\n",
    "from src.read_data import build_data\n",
    "from src.make_features import train_test, standardize_data, data_loader\n",
    "#from src.train import train_model, print_acc\n",
    "\n",
    "from torch_geometric.data import Data, TemporalData, HeteroData\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "\n",
    "def norm_adj(train_graphs, test_graphs):\n",
    "    for i in range(train_graphs.shape[0]):\n",
    "        for j in range(train_graphs.shape[1]):\n",
    "                min_ = (train_graphs[i, j, :, :]).min()\n",
    "                max_ = (train_graphs[i, j, :, :]).max()\n",
    "                train_graphs[i, j, :,  :] = (train_graphs[i, j, :,  :] - min_)/(max_ - min_)\n",
    "                \n",
    "    for i in range(test_graphs.shape[0]):\n",
    "        for j in range(test_graphs.shape[1]):\n",
    "            min_ = (test_graphs[i, j, :, :]).min()\n",
    "            max_ = (test_graphs[i, j, :, :]).max()\n",
    "            test_graphs[i, j, :, :] = (test_graphs[i, j, :,  :] - min_)/(max_ - min_)\n",
    "            \n",
    "    return train_graphs, test_graphs\n",
    "    \n",
    "SAVED_DATA = True\n",
    "SAVED_FEATURES = False\n",
    "CONN_TYPES = [\"coh\"]#, \"ciplv\", \"coh\", \"pc\"]\n",
    "NUM_EPOCHS = 30 #This is based on Cross validation experiments\n",
    "BATCH_SIZE = 128\n",
    "DEVICE = torch.device(\"cpu\") #torch.device(\"mps\")\n",
    "\n",
    "for conn in CONN_TYPES:    \n",
    "    print(conn)\n",
    "    if SAVED_FEATURES:\n",
    "        train_X = np.load(\"../saved_npy_ep/features/train_X.npy\") #samples, #epochs, #channels, #time points)\n",
    "        train_y = np.load(\"../saved_npy_ep/features/train_y.npy\")\n",
    "        train_graphs = np.load(\"../saved_npy_ep/features/train_graphs_\"+conn+\".npy\")\n",
    "        test_y = np.load(\"../saved_npy_ep/features/test_y.npy\")\n",
    "        test_X = np.load(\"../saved_npy_ep/features/test_X.npy\")\n",
    "        test_graphs = np.load(\"../saved_npy_ep/features/test_graphs_\"+conn+\".npy\")\n",
    "        train_X = np.moveaxis(train_X, 1, -1)\n",
    "        test_X = np.moveaxis(test_X, 1, -1)\n",
    "        train_graphs, test_graphs = norm_adj(train_graphs, test_graphs)\n",
    "        #train_X, test_X = standardize_data(train_X, test_X)\n",
    "        \n",
    "    else:\n",
    "        if SAVED_DATA:\n",
    "            # Saved arrays on disk\n",
    "            train_X_files = [\"../saved_npy_ep/features/train_X\"+str(i)+\".npy\" for i in range(0, len(train_files), 100)]\n",
    "            train_y_files = [\"../saved_npy_ep/features/train_y\"+str(i)+\".npy\" for i in range(0, len(train_files), 100)]\n",
    "            train_X = np.vstack([np.load(file).astype(np.float16) for i, file in enumerate(train_X_files)])\n",
    "            train_y = np.vstack([np.load(file).astype(np.float16) for i, file in enumerate(train_y_files)])\n",
    "            test_X = np.load(\"../saved_npy_ep/features/test_X.npy\").astype(np.float16)\n",
    "            test_y = np.load(\"../saved_npy_ep/features/test_y.npy\").astype(np.float16)\n",
    "            \n",
    "        else:\n",
    "            num_windows = 60\n",
    "            window_size = 200\n",
    "            for i in range(0, len(train_files), 100):\n",
    "                train_X, train_y = build_data(train_files[i:i+100], use_windows=False, \n",
    "                                              window_size=window_size, num_windows=num_windows,\n",
    "                                              dataset = \"epilepsy\")\n",
    "                np.save(\"../saved_npy_ep/features/train_X\"+str(i)+\".npy\", train_X.astype(np.float16))\n",
    "                np.save(\"../saved_npy_ep/features/train_y\"+str(i)+\".npy\", train_y.astype(np.float16))\n",
    "            test_X, test_y = build_data(test_files, use_windows=False, window_size=window_size, \n",
    "                                        num_windows=num_windows, dataset = \"epilepsy\")\n",
    "            np.save(\"../saved_npy_ep/features/test_X.npy\", test_X.astype(np.float16))\n",
    "            np.save(\"../saved_npy_ep/features/test_y.npy\", test_y.astype(np.float16))\n",
    "            clear_output()\n",
    "    \n",
    "            train_X_files = [\"../saved_npy_ep/features/train_X\"+str(i)+\".npy\" for i in range(0, len(train_files), 100)]\n",
    "            train_y_files = [\"../saved_npy_ep/features/train_y\"+str(i)+\".npy\" for i in range(0, len(train_files), 100)]\n",
    "            train_X = np.vstack([np.load(file) for file in train_X_files])\n",
    "            train_y = np.vstack([np.load(file) for file in train_y_files])\n",
    "            test_X = np.load(\"../saved_npy_ep/features/test_X.npy\")\n",
    "            test_y = np.load(\"../saved_npy_ep/features/test_y.npy\")\n",
    "\n",
    "        np.save(\"../saved_npy_ep/features/train_X.npy\", train_X)\n",
    "        np.save(\"../saved_npy_ep/features/train_y.npy\", train_y)\n",
    "        np.save(\"../saved_npy_ep/features/test_y.npy\", test_y)\n",
    "        np.save(\"../saved_npy_ep/features/test_X.npy\", test_X)\n",
    "        print(\"make features\")\n",
    "        _ , train_graphs, _, _ , test_graphs, _ = train_test(train_X=train_X, \n",
    "                                                             test_X=test_X, \n",
    "                                                             train_y=train_y, \n",
    "                                                             test_y=test_y, \n",
    "                                                             method=conn)\n",
    "        \n",
    "        np.save(\"../saved_npy_ep/features/train_X.npy\", train_X)\n",
    "        np.save(\"../saved_npy_ep/features/train_y.npy\", train_y)\n",
    "        np.save(\"../saved_npy_ep/features/train_graphs_\"+conn+\".npy\", train_graphs)\n",
    "        np.save(\"../saved_npy_ep/features/test_y.npy\", test_y)\n",
    "        np.save(\"../saved_npy_ep/features/test_X.npy\", test_X)\n",
    "        np.save(\"../saved_npy_ep/features/test_graphs_\"+conn+\".npy\", test_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da2674fe-2a83-4492-bddb-46e4778ef2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1518, 353)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list(train_y.squeeze())\n",
    "x.count(1), x.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "142064dc-fe63-4f89-9f90-2fef7a8f4b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m__MACOSX\u001b[m\u001b[m                        \u001b[34mmci_ad_dataset_npy\u001b[m\u001b[m\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m                     \u001b[34mmci_dem_dataset\u001b[m\u001b[m\n",
      "AD_mci_dataset.ipynb            model.py\n",
      "chrononet_pytorch.ipynb         \u001b[34mmultiedge\u001b[m\u001b[m\n",
      "\u001b[34mclean_code\u001b[m\u001b[m                      node2vec_tuh.ipynb\n",
      "clean_code.zip                  openneuro.ipynb\n",
      "corr-caueeg-MCI_chrononet.ipynb plot.py\n",
      "corr-caueeg-MCI.ipynb           process.py\n",
      "dementia1.ipynb                 read_data.py\n",
      "evaluate.py                     \u001b[34msaved_models\u001b[m\u001b[m\n",
      "explain.py                      \u001b[34msaved_npy_ep\u001b[m\u001b[m\n",
      "\u001b[34meye_tracking\u001b[m\u001b[m                    \u001b[34msaved_npy_tuh\u001b[m\u001b[m\n",
      "\u001b[34mgithub_repo\u001b[m\u001b[m                     \u001b[34mseizure_raw\u001b[m\u001b[m\n",
      "\u001b[34mgraphs\u001b[m\u001b[m                          tgn.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a09d8df-974f-412c-9b6d-a2969e116c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_X = np.load(\"saved_npy_tuh/train_X.npy\")[:10]\n",
    "test_X = np.load(\"saved_npy_tuh/test_X.npy\")[:10]\n",
    "train_y = np.load(\"saved_npy_tuh/train_y.npy\")\n",
    "test_y = np.load(\"saved_npy_tuh/test_y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76ca2838-a388-464a-8d69-171a8050f357",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "80%|███████████████████████████████████▏        | 8/10 [00:14<00:03,  1.84s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_entropy\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tqdm(train_X):\n\u001b[0;32m---> 23\u001b[0m     maxen \u001b[38;5;241m=\u001b[39m \u001b[43mcal_ent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 15\u001b[0m, in \u001b[0;36mcal_ent\u001b[0;34m(signals)\u001b[0m\n\u001b[1;32m     13\u001b[0m appr \u001b[38;5;241m=\u001b[39m nk\u001b[38;5;241m.\u001b[39mentropy_approximate(period_signal)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#appr = nk.entropy_approximate(period_signal)[0]\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m spec \u001b[38;5;241m=\u001b[39m \u001b[43mnk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentropy_spectral\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperiod_signal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     16\u001b[0m entropies \u001b[38;5;241m=\u001b[39m [shan, tsa]\n\u001b[1;32m     17\u001b[0m entropy\u001b[38;5;241m.\u001b[39mappend(entropies)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dyn_graph/lib/python3.10/site-packages/neurokit2/complexity/entropy_spectral.py:88\u001b[0m, in \u001b[0;36mentropy_spectral\u001b[0;34m(signal, bins, show, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultidimensional inputs (e.g., matrices or multichannel data) are not supported yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m     )\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Power-spectrum density (PSD) (actual sampling rate does not matter)\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m psd \u001b[38;5;241m=\u001b[39m \u001b[43msignal_psd\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Cut into bins\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(bins, \u001b[38;5;28mint\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dyn_graph/lib/python3.10/site-packages/neurokit2/signal/signal_psd.py:208\u001b[0m, in \u001b[0;36msignal_psd\u001b[0;34m(signal, sampling_rate, method, show, normalize, min_frequency, max_frequency, window, window_type, order, order_criteria, order_corrected, silent, t, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m     power \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(power)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# Store results\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFrequency\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPower\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpower\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# Filter\u001b[39;00m\n\u001b[1;32m    211\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mloc[np\u001b[38;5;241m.\u001b[39mlogical_and(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrequency\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m min_frequency, data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrequency\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_frequency)]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dyn_graph/lib/python3.10/site-packages/pandas/core/frame.py:614\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    608\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    609\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    610\u001b[0m     )\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 614\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dyn_graph/lib/python3.10/site-packages/pandas/core/internals/construction.py:464\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    456\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    457\u001b[0m         x\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    460\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m    461\u001b[0m     ]\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dyn_graph/lib/python3.10/site-packages/pandas/core/internals/construction.py:135\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    132\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_block_manager_from_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidate\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(arrays):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dyn_graph/lib/python3.10/site-packages/pandas/core/internals/managers.py:1773\u001b[0m, in \u001b[0;36mcreate_block_manager_from_arrays\u001b[0;34m(arrays, names, axes, consolidate)\u001b[0m\n\u001b[1;32m   1770\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [_extract_array(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     blocks \u001b[38;5;241m=\u001b[39m \u001b[43m_form_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1774\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m BlockManager(blocks, axes)\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dyn_graph/lib/python3.10/site-packages/pandas/core/internals/managers.py:1833\u001b[0m, in \u001b[0;36m_form_blocks\u001b[0;34m(arrays, names, axes, consolidate)\u001b[0m\n\u001b[1;32m   1829\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1831\u001b[0m     v \u001b[38;5;241m=\u001b[39m arrays[name_idx]\n\u001b[0;32m-> 1833\u001b[0m     block_type \u001b[38;5;241m=\u001b[39m \u001b[43mget_block_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1834\u001b[0m     items_dict[block_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m]\u001b[38;5;241m.\u001b[39mappend((i, v))\n\u001b[1;32m   1836\u001b[0m blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dyn_graph/lib/python3.10/site-packages/pandas/core/internals/blocks.py:1911\u001b[0m, in \u001b[0;36mget_block_type\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m   1907\u001b[0m kind \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mkind\n\u001b[1;32m   1909\u001b[0m \u001b[38;5;28mcls\u001b[39m: \u001b[38;5;28mtype\u001b[39m[Block]\n\u001b[0;32m-> 1911\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1912\u001b[0m     \u001b[38;5;66;03m# Need this first(ish) so that Sparse[datetime] is sparse\u001b[39;00m\n\u001b[1;32m   1913\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m ExtensionBlock\n\u001b[1;32m   1914\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, CategoricalDtype):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dyn_graph/lib/python3.10/site-packages/pandas/core/dtypes/common.py:234\u001b[0m, in \u001b[0;36mis_sparse\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03mCheck whether an array-like is a 1-D pandas sparse array.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03mReturns `False` if the parameter has more than one dimension.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m--> 234\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, SparseDtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import neurokit2 as nk\n",
    "from tqdm import tqdm\n",
    "def cal_ent(signals):\n",
    "    all_entropy = []\n",
    "    for ch_signals in signals:\n",
    "        entropy = []\n",
    "        for period_signal in ch_signals:\n",
    "            maxen = nk.entropy_maximum(period_signal)[0]\n",
    "            diff = nk.entropy_differential(period_signal)[0]\n",
    "            power = nk.entropy_power(period_signal)[0]\n",
    "            tsa =  nk.entropy_tsallis(period_signal, q=1)[0]\n",
    "            shan = nk.entropy_shannon(period_signal, base=np.e)[0]\n",
    "            appr = nk.entropy_approximate(period_signal)[0]\n",
    "            #appr = nk.entropy_approximate(period_signal)[0]\n",
    "            spec = nk.entropy_spectral(period_signal, show=False)[0]\n",
    "            entropies = [shan, tsa]\n",
    "            entropy.append(entropies)\n",
    "        all_entropy.append(entropy)\n",
    "\n",
    "    return all_entropy\n",
    "\n",
    "for x in tqdm(train_X):\n",
    "    maxen = cal_ent(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "faae186c-69c7-465c-8074-7ce9706819b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.925"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15/10*2717/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "addd2ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from tqdm import tqdm\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter, detrend\n",
    "from scipy import signal\n",
    "\n",
    "import numpy as np\n",
    "import scipy.signal as sig\n",
    "\n",
    "from braindecode.preprocessing import exponential_moving_standardize\n",
    "\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "def get_label(file):\n",
    "    label = file.split(\"/\")[-5]\n",
    "    if label == \"no_epilepsy_edf\":\n",
    "        return [0]\n",
    "    elif label == \"epilepsy_edf\":\n",
    "        return [1]\n",
    "\n",
    "def multichannel_sliding_window(X, size, step):\n",
    "    shape = (X.shape[0] - X.shape[0] + 1, (X.shape[1] - size + 1) // step, X.shape[0], size)\n",
    "    strides = (X.strides[0], X.strides[1] * step, X.strides[0], X.strides[1])\n",
    "    return np.lib.stride_tricks.as_strided(X, shape, strides)[0]\n",
    "\n",
    "    \n",
    "def read_edf_file(file, use_windows=True, num_windows=100): \n",
    "    \n",
    "    try:\n",
    "        data_raw = mne.io.read_raw_edf(file, preload=True)\n",
    "        channels_to_use = [\"FP1\", \"FP2\", \"F7\", \"F3\", \"FZ\", \"F4\", \"F8\",\n",
    "                                  \"T3\", \"C3\", \"CZ\", \"C4\", \"T4\", \"T5\",\n",
    "                                  \"P3\", \"PZ\", \"P4\", \"T6\", \"O1\", \"O2\"]\n",
    "        ch_name_update_func = lambda ch: ch.split(' ')[-1].split('-')[0]\n",
    "        data_raw.rename_channels(mapping=ch_name_update_func)\n",
    "        data_raw = data_raw.pick_channels(channels_to_use, ordered=True)\n",
    "        montage = mne.channels.make_standard_montage('standard_1020')\n",
    "        data_raw.set_montage(montage, match_case=False, match_alias=True)\n",
    "        data_raw.filter(l_freq=1.0, h_freq=45.0)\n",
    "        data_raw.resample(100, npad='auto')\n",
    "        data_raw = data_raw.get_data()\n",
    "        #data_raw = np.diff(data_raw, axis=-1)\n",
    "        data_raw = multichannel_sliding_window(data_raw, 100, 90)\n",
    "    except:\n",
    "        return \n",
    "    startpoint = 10\n",
    "    \n",
    "    if data_raw.shape[0] >= num_windows+startpoint:\n",
    "        return [data_raw[startpoint:num_windows+startpoint, :, :]]\n",
    "    else:\n",
    "        return\n",
    "\n",
    "\n",
    "def build_data(raw_data, use_windows=True, num_windows=200):\n",
    "    \n",
    "    all_data_features = []\n",
    "    data_labels = []\n",
    "    data_graphs = []\n",
    "    \n",
    "    for file in tqdm(raw_data):\n",
    "        edf_data = read_edf_file(file, use_windows=use_windows, num_windows=num_windows)\n",
    "        if not edf_data:\n",
    "            continue\n",
    "        else:\n",
    "            for edf_data1 in edf_data:\n",
    "                all_data_features.append(edf_data1)\n",
    "                label = get_label(file)\n",
    "                data_labels.append(np.array(label))\n",
    "    \n",
    "    all_data_features = np.array(all_data_features)\n",
    "    data_labels = np.array(data_labels)\n",
    "             \n",
    "    return all_data_features, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1939d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#from train import trainer\n",
    "import torch\n",
    "#from tgcn import TGCN\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from scipy import signal\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from scipy.sparse import csgraph\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import spkit as sp\n",
    "\n",
    "\n",
    "def hilphase(x1,x2):\n",
    "    sig1_hill=sig.hilbert(x1)\n",
    "    sig2_hill=sig.hilbert(x2)\n",
    "    pdt=(np.inner(sig1_hill,np.conj(sig2_hill))/(np.sqrt(np.inner(sig1_hill,\n",
    "               np.conj(sig1_hill))*np.inner(sig2_hill,np.conj(sig2_hill)))))\n",
    "    phase = np.angle(pdt)\n",
    "    return phase\n",
    "    \n",
    "def gc(x1, x2):\n",
    "    X = np.vstack([x1, x2]).T\n",
    "    gc = grangercausalitytests(X, [2], addconst=True, verbose=False)[2][0]['ssr_ftest'][1]\n",
    "    return gc\n",
    "    \n",
    "    \n",
    "# Coherence - δ\n",
    "def coherence(eegData,fs):\n",
    "    coh_res = []\n",
    "    for ii, jj in itertools.combinations(range(eegData.shape[0]), 2):\n",
    "        coh_res.append(CoherenceDelta(eegData, ii, jj, fs=fs))\n",
    "    coh_res = np.array(coh_res)\n",
    "    return coh_res\n",
    "\n",
    "# Mutual information\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "# https://github.com/ufvceiec/EEGRAPH/blob/develop-refactor/eegraph/strategy.py\n",
    "def pli(data_intervals, i, j):\n",
    "    sig1_phase = signal.hilbert([data_intervals[i]])\n",
    "    sig2_phase = signal.hilbert([data_intervals[j]])\n",
    "    phase_diff = sig1_phase[0] - sig2_phase[0]\n",
    "    phase_diff = phase_diff.astype(float)\n",
    "    phase_diff = (phase_diff  + np.pi) % (2 * np.pi) - np.pi\n",
    "    pli = abs(np.mean(np.sign(phase_diff)))\n",
    "    return pli\n",
    "    \n",
    "\n",
    "# Cross correlation \n",
    "# https://github.com/ufvceiec/EEGRAPH/blob/develop-refactor/eegraph/strategy.py\n",
    "def calculate_cc(data_intervals, i, j):\n",
    "    x = data_intervals[i]\n",
    "    y = data_intervals[j]\n",
    "    \n",
    "    Rxy = signal.correlate(x,y, 'full')\n",
    "    Rxx = signal.correlate(x,x, 'full')\n",
    "    Ryy = signal.correlate(y,y, 'full')\n",
    "    \n",
    "    lags = np.arange(-len(data_intervals[i]) + 1, len(data_intervals[i]))\n",
    "    lag_0 = int((np.where(lags==0))[0])\n",
    "\n",
    "    Rxx_0 = Rxx[lag_0]\n",
    "    Ryy_0 = Ryy[lag_0]\n",
    "    \n",
    "    Rxy_norm = (1/(np.sqrt(Rxx_0*Ryy_0)))* Rxy\n",
    "    #We use the mean from lag 0 to a 10% displacement. \n",
    "    disp = round((len(data_intervals[i])) * 0.10)\n",
    "    cc_coef = Rxy_norm[lag_0: lag_0 + disp].mean()\n",
    "    return cc_coef\n",
    "     \n",
    "def cal_mi(x1, x2):\n",
    "    x1 = x1.reshape(x1.shape[0], 1)\n",
    "    mi = mutual_info_regression(x1, x2)\n",
    "    return mi\n",
    "\n",
    "\n",
    "# Mutual information\n",
    "def calculate2Chan_MI(eegData,ii,jj,bin_min=-200, bin_max=200, binWidth=2):\n",
    "    H = np.zeros(eegData.shape[2])\n",
    "    bins = np.arange(bin_min+1, bin_max, binWidth)\n",
    "    for epoch in range(eegData.shape[2]):\n",
    "        c_xy = np.histogram2d(eegData[ii,:,epoch],eegData[jj,:,epoch],bins)[0]\n",
    "        H[epoch] = mutual_info_score(None, None, contingency=c_xy)\n",
    "    return H\n",
    "\n",
    "\n",
    "import spkit as sp\n",
    "\n",
    "def gen_graphs(eegs, num_nodes=19, cal_conn=\"cc\"):\n",
    "    #eegs(snapshots, bands, timpoints)\n",
    "    c = []\n",
    "    for i in range(num_nodes):\n",
    "        c1 = []\n",
    "        for j in range(num_nodes):\n",
    "            if cal_conn == \"pearson\":\n",
    "                conn = pearsonr(eegs[i], eegs[j])[0]\n",
    "            elif cal_conn == \"cc\":\n",
    "                conn = calculate_cc(eegs, i, j)\n",
    "            elif cal_conn == \"plv\": \n",
    "                conn = hilphase(eegs[i], eegs[j])\n",
    "            elif cal_conn == \"pli\":\n",
    "                conn = pli(eegs, i, j)\n",
    "            elif cal_conn == \"gc\": \n",
    "                conn = gc(eegs[i], eegs[j])\n",
    "            elif cal_conn == \"mi\": \n",
    "                conn = sp.mutual_info(eegs[i], eegs[j])\n",
    "            elif cal_conn == \"con-entropy\": \n",
    "                conn = sp.entropy_cond(eegs[i],eegs[j])\n",
    "            elif cal_conn == \"cross-entropy\": \n",
    "                conn = sp.entropy_cross(eegs[i],eegs[j])\n",
    "            elif cal_conn == \"kld-entropy\": \n",
    "                conn = sp.entropy_kld(eegs[i],eegs[j])\n",
    "            elif cal_conn == \"joint-entropy\": \n",
    "                conn = sp.entropy_joint(eegs[i],eegs[j])\n",
    "            c1.append(conn)\n",
    "        c.append(c1)\n",
    "    return c\n",
    "\n",
    "\n",
    "def gen_features(X, y, device, cal_conn, window_size=100, overlap=0, augment=False, stft=False):\n",
    "    X_new = np.moveaxis(np.array(X), 1, -1)\n",
    "    graphs = []\n",
    "    dynamic_range = X_new.shape[-1]\n",
    "    threshold = 0.3\n",
    "    \n",
    "    print(\"calculating connectivity\")\n",
    "    for x in tqdm(X_new):\n",
    "        temp = []\n",
    "        for i in range(dynamic_range):\n",
    "            temp_g = gen_graphs(x[:, :, i], cal_conn=cal_conn)\n",
    "            temp_g = np.array(temp_g).squeeze()\n",
    "            #temp_g = (temp_g - temp_g.min())/(temp_g.max() - temp_g.min())\n",
    "            #temp_g[temp_g<threshold] = 0\n",
    "            #temp_g = csgraph.laplacian(temp_g)\n",
    "            temp.append(temp_g)\n",
    "        graphs.append(temp)\n",
    "        \n",
    "    \n",
    "    # calculate STFT\n",
    "    X_new = np.moveaxis(X_new, -1, 1)\n",
    "    X = []\n",
    "    for x in X_new:\n",
    "        f, t, Zxx = signal.stft(x, 100, nperseg=100, noverlap=10, boundary=None, padded=None)\n",
    "        X.append(np.abs(Zxx))\n",
    "        #X.append(x)\n",
    "        \n",
    "    X_new = np.array(X).squeeze()\n",
    "    X_new = np.moveaxis(np.array(X_new), 1, -1)    \n",
    "    graphs = np.array(graphs)\n",
    "    \n",
    "    graphs = np.moveaxis(graphs.squeeze(), 1, -1)\n",
    "        \n",
    "    return X_new, graphs, y\n",
    "\n",
    "import copy\n",
    "def standardize_data(train_X, test_X):\n",
    "    train_X_std = copy.deepcopy(train_X)\n",
    "    test_X_std = copy.deepcopy(test_X)\n",
    "    for i in range(train_X.shape[2]):\n",
    "        min_ = np.min(train_X[:, :, i, :])\n",
    "        max_ = np.max(train_X[:, :, i, :])\n",
    "        train_X_std[:, :, i, :] = (train_X[:, :, i, :] - min_)/(max_ - min_)\n",
    "        test_X_std[:, :, i, :] = (test_X[:, :, i, :] - min_)/(max_ - min_)\n",
    "    return train_X_std, test_X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67f470c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "import torch.nn as nn\n",
    "from torch_scatter import scatter_add\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "class TGCN(torch.nn.Module):\n",
    "    r\"\"\"An implementation of the Temporal Graph Convolutional Gated Recurrent Cell.\n",
    "    For details see this paper: `\"T-GCN: A Temporal Graph ConvolutionalNetwork for\n",
    "    Traffic Prediction.\" <https://arxiv.org/abs/1811.05320>`_\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input features.\n",
    "        out_channels (int): Number of output features.\n",
    "        improved (bool): Stronger self loops. Default is False.\n",
    "        cached (bool): Caching the message weights. Default is False.\n",
    "        add_self_loops (bool): Adding self-loops for smoothing. Default is True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        improved: bool = False,\n",
    "        cached: bool = False,\n",
    "        add_self_loops: bool = True,\n",
    "    ):\n",
    "        super(TGCN, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.improved = improved\n",
    "        self.cached = cached\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        self._create_parameters_and_layers()\n",
    "\n",
    "    def _create_update_gate_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_z = GCNConv(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            improved=self.improved,\n",
    "            cached=self.cached,\n",
    "            add_self_loops=self.add_self_loops,\n",
    "        )\n",
    "\n",
    "        self.linear_z = torch.nn.Linear(2 * self.out_channels, self.out_channels)\n",
    "\n",
    "    def _create_reset_gate_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_r = GCNConv(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            improved=self.improved,\n",
    "            cached=self.cached,\n",
    "            add_self_loops=self.add_self_loops,\n",
    "        )\n",
    "\n",
    "        self.linear_r = torch.nn.Linear(2 * self.out_channels, self.out_channels)\n",
    "\n",
    "    def _create_candidate_state_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_h = GCNConv(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            improved=self.improved,\n",
    "            cached=self.cached,\n",
    "            add_self_loops=self.add_self_loops,\n",
    "        )\n",
    "\n",
    "        self.linear_h = torch.nn.Linear(2 * self.out_channels, self.out_channels)\n",
    "\n",
    "    def _create_parameters_and_layers(self):\n",
    "        self._create_update_gate_parameters_and_layers()\n",
    "        self._create_reset_gate_parameters_and_layers()\n",
    "        self._create_candidate_state_parameters_and_layers()\n",
    "\n",
    "    def _set_hidden_state(self, X, H):\n",
    "        if H is None:\n",
    "            H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n",
    "        return H\n",
    "\n",
    "    def _calculate_update_gate(self, X, edge_index, edge_weight, H):\n",
    "        Z = torch.cat([self.conv_z(X, edge_index, edge_weight), H], axis=1)\n",
    "        Z = self.linear_z(Z)\n",
    "        Z = torch.sigmoid(Z)\n",
    "        return Z\n",
    "\n",
    "    def _calculate_reset_gate(self, X, edge_index, edge_weight, H):\n",
    "        R = torch.cat([self.conv_r(X, edge_index, edge_weight), H], axis=1)\n",
    "        R = self.linear_r(R)\n",
    "        R = torch.sigmoid(R)\n",
    "        return R\n",
    "\n",
    "    def _calculate_candidate_state(self, X, edge_index, edge_weight, H, R):\n",
    "        H_tilde = torch.cat([self.conv_h(X, edge_index, edge_weight), H * R], axis=1)\n",
    "        H_tilde = self.linear_h(H_tilde)\n",
    "        H_tilde = torch.tanh(H_tilde)\n",
    "        return H_tilde\n",
    "\n",
    "    def _calculate_hidden_state(self, Z, H, H_tilde):\n",
    "        H = Z * H + (1 - Z) * H_tilde\n",
    "        return H\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        X: torch.FloatTensor,\n",
    "        edge_index: torch.LongTensor,\n",
    "        edge_weight: torch.FloatTensor = None,\n",
    "        H: torch.FloatTensor = None,\n",
    "    ) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        Making a forward pass. If edge weights are not present the forward pass\n",
    "        defaults to an unweighted graph. If the hidden state matrix is not present\n",
    "        when the forward pass is called it is initialized with zeros.\n",
    "\n",
    "        Arg types:\n",
    "            * **X** *(PyTorch Float Tensor)* - Node features.\n",
    "            * **edge_index** *(PyTorch Long Tensor)* - Graph edge indices.\n",
    "            * **edge_weight** *(PyTorch Long Tensor, optional)* - Edge weight vector.\n",
    "            * **H** *(PyTorch Float Tensor, optional)* - Hidden state matrix for all nodes.\n",
    "\n",
    "        Return types:\n",
    "            * **H** *(PyTorch Float Tensor)* - Hidden state matrix for all nodes.\n",
    "        \"\"\"\n",
    "        H = self._set_hidden_state(X, H)\n",
    "        Z = self._calculate_update_gate(X, edge_index, edge_weight, H)\n",
    "        R = self._calculate_reset_gate(X, edge_index, edge_weight, H)\n",
    "        H_tilde = self._calculate_candidate_state(X, edge_index, edge_weight, H, R)\n",
    "        H = self._calculate_hidden_state(Z, H, H_tilde)\n",
    "        return H\n",
    "    \n",
    "    \n",
    "    \n",
    "class A3TGCN(torch.nn.Module):\n",
    "    r\"\"\"An implementation of the Attention Temporal Graph Convolutional Cell.\n",
    "    For details see this paper: `\"A3T-GCN: Attention Temporal Graph Convolutional\n",
    "    Network for Traffic Forecasting.\" <https://arxiv.org/abs/2006.11583>`_\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input features.\n",
    "        out_channels (int): Number of output features.\n",
    "        periods (int): Number of time periods.\n",
    "        improved (bool): Stronger self loops (default :obj:`False`).\n",
    "        cached (bool): Caching the message weights (default :obj:`False`).\n",
    "        add_self_loops (bool): Adding self-loops for smoothing (default :obj:`True`).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        periods: int,\n",
    "        improved: bool = False,\n",
    "        cached: bool = False,\n",
    "        add_self_loops: bool = True\n",
    "    ):\n",
    "        super(A3TGCN, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.periods = periods\n",
    "        self.improved = improved\n",
    "        self.cached = cached\n",
    "        self.add_self_loops = add_self_loops\n",
    "        self._setup_layers()\n",
    "\n",
    "    def _setup_layers(self):\n",
    "        self._base_tgcn = TGCN(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            improved=self.improved,\n",
    "            cached=self.cached,\n",
    "            add_self_loops=self.add_self_loops,\n",
    "        )\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.attention = torch.nn.Parameter(torch.empty(self.periods, device=device))\n",
    "        torch.nn.init.uniform_(self.attention)\n",
    "        \n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        X: torch.FloatTensor,\n",
    "        A: torch.FloatTensor,\n",
    "        H: torch.FloatTensor = None,\n",
    "    ) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        Making a forward pass. If edge weights are not present the forward pass\n",
    "        defaults to an unweighted graph. If the hidden state matrix is not present\n",
    "        when the forward pass is called it is initialized with zeros.\n",
    "\n",
    "        Arg types:\n",
    "            * **X** (PyTorch Float Tensor): Node features for T time periods.\n",
    "            * **edge_index** (PyTorch Long Tensor): Graph edge indices.\n",
    "            * **edge_weight** (PyTorch Long Tensor, optional)*: Edge weight vector.\n",
    "            * **H** (PyTorch Float Tensor, optional): Hidden state matrix for all nodes.\n",
    "\n",
    "        Return types:\n",
    "            * **H** (PyTorch Float Tensor): Hidden state matrix for all nodes.\n",
    "        \"\"\"\n",
    "        \n",
    "        H_accum = 0\n",
    "        probs = torch.nn.functional.softmax(self.attention, dim=0)\n",
    "        for period in range(self.periods):\n",
    "            Xt = X[:, :, :, period]\n",
    "            batch_size = Xt.shape[0]\n",
    "            Xt = Xt.reshape(Xt.shape[0]*Xt.shape[1], Xt.shape[-1])\n",
    "            At = A[:, :, :, period]\n",
    "            At = torch.block_diag(*At)\n",
    "            idx = (At > 0).nonzero().t().contiguous().long().to(X.device)\n",
    "            row, col = idx\n",
    "            w = At[row, col].float().to(X.device)            \n",
    "            temp_emb = self._base_tgcn(Xt, idx, w, H)\n",
    "            temp_emb = temp_emb.reshape(batch_size, 19, 32)\n",
    "            \n",
    "            H_accum = H_accum + probs[period] * temp_emb #([32, 207, 32]\n",
    "            \n",
    "        return H_accum\n",
    "    \n",
    "class EEGModel(nn.Module):\n",
    "    def __init__(self, num_nodes, node_features, num_classes, num_windows, device):\n",
    "        super(EEGModel, self).__init__()\n",
    "        self.forwardA3TGCN = A3TGCN(in_channels=node_features, out_channels=32, periods=num_windows) # node_features=2, periods=12\n",
    "        self.backwardA3TGCN = A3TGCN(in_channels=node_features, out_channels=32, periods=num_windows) # node_features=2, periods=12\n",
    "        self.num_nodes = num_nodes\n",
    "        self.BN = nn.BatchNorm1d(self.num_nodes)\n",
    "        self.num_windows = num_windows\n",
    "        self.fc2 = nn.Linear(self.num_nodes*64, num_classes)\n",
    "        \n",
    "    def forward(self, X, A):\n",
    "        HS1 = self.forwardA3TGCN(X, A)\n",
    "        X_flip = torch.flip(X, dims=[1])\n",
    "        A_flip = torch.flip(A, dims=[1])\n",
    "        HS2 = self.backwardA3TGCN(X_flip, A_flip)\n",
    "        HS = torch.cat((HS1, HS2), -1)\n",
    "        HS = nn.functional.relu(HS)\n",
    "        HS = self.BN(HS)\n",
    "        HS = HS.reshape(HS.shape[0], self.num_nodes*64)\n",
    "        out = self.fc2(HS)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "357e2a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import copy\n",
    "\n",
    "\n",
    "def standardize_data(train_X, test_X):\n",
    "    train_X_std = copy.deepcopy(train_X)\n",
    "    test_X_std = copy.deepcopy(test_X)\n",
    "    for i in range(train_X.shape[1]):\n",
    "        min_ = np.min(train_X[:, i, :, :])\n",
    "        max_ = np.max(train_X[:, i, :, :])\n",
    "        train_X_std[:, i, :, :] = (train_X[:, i, :, :] - min_)/(max_ - min_)\n",
    "        test_X_std[:, i, :, :] = (test_X[:, i, :, :] - min_)/(max_ - min_)\n",
    "    return train_X_std, test_X_std\n",
    "\n",
    "\n",
    "def standardize_data(train_X, test_X):\n",
    "    train_X_std = copy.deepcopy(train_X)\n",
    "    test_X_std = copy.deepcopy(test_X)\n",
    "    for i in range(train_X.shape[1]):\n",
    "        for j in range(train_X.shape[2]):\n",
    "            min_ = np.min(train_X[:, i, j, :])\n",
    "            max_ = np.max(train_X[:, i, j, :])\n",
    "            train_X_std[:, i, j, :] = (train_X[:, i, j, :] - min_)/(max_ - min_)\n",
    "            test_X_std[:, i, j, :] = (test_X[:, i, j, :] - min_)/(max_ - min_)\n",
    "    return train_X_std, test_X_std\n",
    "\n",
    "\n",
    "def train_test(train_X, test_X, train_y, test_y, cal_conn, device, use_test_windows=False):\n",
    "    print(\"read_data\")\n",
    "    \n",
    "    print(train_X.shape, test_X.shape)\n",
    "    \n",
    "    train_X, train_graphs, train_y = gen_features(train_X, train_y, device, cal_conn=cal_conn, \n",
    "                                                  window_size=100, overlap=90, augment=False)\n",
    "    test_X, test_graphs, test_y = gen_features(test_X, test_y, device, cal_conn=cal_conn, \n",
    "                                               window_size=100, overlap=90, augment=False)\n",
    "    \n",
    "    train_X, test_X = standardize_data(train_X, test_X)\n",
    "    \n",
    "    clear_output()\n",
    "    encoder = OneHotEncoder()\n",
    "    train_y = encoder.fit_transform(train_y).toarray()\n",
    "    test_y = encoder.transform(test_y).toarray()\n",
    "    train_X = torch.Tensor(train_X).to(DEVICE)\n",
    "    test_X = torch.Tensor(test_X).to(DEVICE)\n",
    "    train_y= torch.Tensor(train_y).to(DEVICE)\n",
    "    test_y = torch.Tensor(test_y).to(DEVICE)\n",
    "    test_graphs= torch.Tensor(test_graphs).to(DEVICE)\n",
    "    train_graphs = torch.Tensor(train_graphs).to(DEVICE)\n",
    "\n",
    "    batch_size = 64\n",
    "    data = TensorDataset(train_X, train_graphs, train_y)\n",
    "    train_iter = torch.utils.data.DataLoader(data, batch_size, shuffle=True)\n",
    "    data = TensorDataset(test_X, test_graphs, test_y)\n",
    "    test_iter = torch.utils.data.DataLoader(data, batch_size, shuffle=False)\n",
    "    \n",
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab63b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "from sklearn.model_selection import KFold\n",
    "    \n",
    "def train_kfold(files_kfold):\n",
    "    all_train_losses = []\n",
    "    all_val_losses = []\n",
    "    \n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=2024)\n",
    "    for k, (train_files_, val_files_) in enumerate(kf.split(files_kfold)):\n",
    "        print(\"Kfold\", k)\n",
    "        train_files_ = [files_kfold[i] for i in train_files_]\n",
    "        val_files_ = [files_kfold[i] for i in val_files_]\n",
    "        train_iter, val_iter = train_test(train_files=train_files_, \n",
    "                                          test_files=val_files_,\n",
    "                                          num_windows=200,\n",
    "                                          cal_conn=\"corr\",\n",
    "                                          use_test_windows=True)\n",
    "        \n",
    "        DEVICE = torch.device('cpu')\n",
    "        model = EEGModel(num_nodes=19, node_features=300, num_classes=2, num_windows=332, device=DEVICE)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "    \n",
    "        print(\"Training model\")\n",
    "        model.train()\n",
    "        for epoch in range(10):\n",
    "            losses = 0\n",
    "            for idx, (X, A, y) in enumerate(tqdm(train_iter)):\n",
    "                optimizer.zero_grad()\n",
    "                out = model(X, A)\n",
    "                loss = criterion(out, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses += loss.item()*X.shape[0]\n",
    "            losses = losses/len(train_iter.dataset)\n",
    "            print(\"Epoch \", epoch+1, \":\")\n",
    "            print(\"Kfold train loss\", losses)\n",
    "            all_train_losses.append(losses)\n",
    "            losses = 0\n",
    "            \n",
    "            for idx, (X, A, y) in enumerate(val_iter):\n",
    "                optimizer.zero_grad()\n",
    "                out = model(X, A)\n",
    "                loss = criterion(out, y)\n",
    "                losses += loss.item()*X.shape[0]\n",
    "            losses = losses/len(val_iter.dataset)\n",
    "            print(\"Kfold val loss\", losses)\n",
    "            all_val_losses.append(losses)\n",
    "    clear_output()\n",
    "    return all_train_losses, all_val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f4fef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "def train_val(files):\n",
    "    all_train_losses = []\n",
    "    all_val_losses = []\n",
    "\n",
    "    train_subset_files, val_files = train_test_split(files, test_size=0.1, random_state=2024)\n",
    "    train_iter, val_iter = train_test(train_files=train_subset_files, \n",
    "                                      test_files=val_files,\n",
    "                                      num_windows=200,\n",
    "                                      cal_conn=\"pearson\",\n",
    "                                      use_test_windows=True)\n",
    "    \n",
    "    DEVICE = torch.device('cpu')\n",
    "    model = EEGModel(num_nodes=19, node_features=51, num_classes=2, num_windows=200, device=DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "\n",
    "    print(\"Training model\")\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        losses = 0\n",
    "        for idx, (X, A, y) in enumerate(tqdm(train_iter)):\n",
    "            optimizer.zero_grad()\n",
    "            out = model(X, A)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses += loss.item()*X.shape[0]\n",
    "        losses = losses/len(train_iter.dataset)\n",
    "        print(\"Epoch \", epoch+1, \":\")\n",
    "        print(\"train loss\", losses)\n",
    "        all_train_losses.append(losses)\n",
    "        \n",
    "        losses = 0\n",
    "        for idx, (X, A, y) in enumerate(val_iter):\n",
    "            optimizer.zero_grad()\n",
    "            out = model(X, A)\n",
    "            loss = criterion(out, y)\n",
    "            losses += loss.item()*X.shape[0]\n",
    "        losses = losses/len(val_iter.dataset)\n",
    "        print(\"val loss\", losses)\n",
    "        all_val_losses.append(losses)\n",
    "    clear_output()\n",
    "    return all_train_losses, all_val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07c75485",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_losses, val_losses = train_val(train_files)\\nimport matplotlib.pyplot as plt\\nplt.plot(train_losses)\\nplt.plot(val_losses)\\nplt.xlim(-1, 100)\\nplt.xlabel(\"epochs\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_losses, val_losses = train_val(train_files)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.xlim(-1, 100)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b58bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, auc, roc_auc_score\n",
    "\n",
    "def print_acc(model, data_iter):\n",
    "    outs= []\n",
    "    ys = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, A, y in data_iter:\n",
    "            out = model(X, A)\n",
    "            outs.extend(out.cpu().detach().numpy())\n",
    "            ys.extend(y.cpu().detach().numpy())\n",
    "    \n",
    "    outs = np.array(outs)\n",
    "    ys = np.array(ys)\n",
    "    outs = np.argmax(outs, -1)\n",
    "    ys = np.argmax(ys, -1)\n",
    "\n",
    "    print(\"accuracy:\", accuracy_score(outs, ys),\n",
    "          \"f1 score:\", f1_score(outs, ys),\n",
    "          \"precision:\",precision_score(outs, ys),\n",
    "          \"recall:\", recall_score(outs, ys),\n",
    "          \"confusion matrix:\", confusion_matrix(outs, ys))\n",
    "\n",
    "    metrics = [accuracy_score(outs, ys), f1_score(outs, ys), \n",
    "               precision_score(outs, ys), recall_score(outs, ys),\n",
    "               confusion_matrix(outs, ys)]\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def train_model(model, num_epochs, data_iter):\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(num_epochs)): \n",
    "        losses = 0\n",
    "        model.train()\n",
    "        for idx, (X, A, y) in enumerate(data_iter):\n",
    "            optimizer.zero_grad()\n",
    "            out = model(X, A)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print_acc(model, test_iter)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ad020f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, auc, roc_auc_score\n",
    "\n",
    "def print_acc(model, data_iter):\n",
    "    outs= []\n",
    "    ys = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, A, y in data_iter:\n",
    "            out = model(X, A)\n",
    "            outs.extend(out.cpu().detach().numpy())\n",
    "            ys.extend(y.cpu().detach().numpy())\n",
    "    \n",
    "    outs = np.array(outs)\n",
    "    ys = np.array(ys)\n",
    "    outs = np.argmax(outs, -1)\n",
    "    ys = np.argmax(ys, -1)\n",
    "\n",
    "    print(\"accuracy:\", accuracy_score(outs, ys),\n",
    "          \"f1 score:\", f1_score(outs, ys),\n",
    "          \"precision:\",precision_score(outs, ys),\n",
    "          \"recall:\", recall_score(outs, ys),\n",
    "          \"confusion matrix:\", confusion_matrix(outs, ys))\n",
    "\n",
    "    metrics = [accuracy_score(outs, ys), f1_score(outs, ys), \n",
    "               precision_score(outs, ys), recall_score(outs, ys),\n",
    "               confusion_matrix(outs, ys)]\n",
    "    return metrics\n",
    "\n",
    "def train_model(model, num_epochs, data_iter):\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs): \n",
    "        losses = 0\n",
    "        model.train()\n",
    "        for idx, (X, A, y) in enumerate(data_iter):\n",
    "            optimizer.zero_grad()\n",
    "            out = model(X, A)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print_acc(model, test_iter)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44efb196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_windows = 50\n",
    "import copy\n",
    "    \n",
    "train_X, train_y = build_data(train_files, use_windows=False, num_windows=num_windows)\n",
    "test_X, test_y = build_data(test_files, use_windows=False, num_windows=num_windows)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "train_iter, test_iter = train_test(train_X=train_X, \n",
    "                                       test_X=test_X, \n",
    "                                       train_y=train_y, \n",
    "                                       test_y=test_y, \n",
    "                                       cal_conn=\"cc\",\n",
    "                                       device=DEVICE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9a061-8993-4a8a-909b-270230f3cac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d934aad2-cbb7-4b1d-84ba-21494fab7265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd17298d-768b-44f1-8724-b77516794183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3990371-723c-4302-acda-ec70e12bca33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1351bbf7-a6f7-430b-9e2a-bf7e2b3435a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425410c6-ab42-471d-a728-2fdda8d4e719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceafc8e-d74a-48fc-a609-aab39975234b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750043e4-95f6-4885-9932-c7e9c6924d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bfcf18-3f41-42fa-bbe5-9cf044579fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b7a3e-d371-4cd9-82ff-540fb9204700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b40ab5-d4e6-4c58-bdfe-0f7f80c5cb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27d2d8d3-68f4-4359-8fe8-49dab61bb3fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.45229681978798586 f1 score: 0.025157232704402517 precision: 0.012987012987012988 recall: 0.4 confusion matrix: [[126 152]\n",
      " [  3   2]]\n",
      "accuracy: 0.5441696113074205 f1 score: 0.7034482758620689 precision: 0.9935064935064936 recall: 0.5444839857651246 confusion matrix: [[  1   1]\n",
      " [128 153]]\n",
      "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
      " [  0   2]]\n",
      "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
      " [  0   2]]\n",
      "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
      " [  0   2]]\n",
      "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
      " [  0   2]]\n",
      "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
      " [  0   2]]\n",
      "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
      " [  0   2]]\n",
      "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
      " [  0   2]]\n",
      "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
      " [  0   2]]\n",
      "accuracy: 0.5477031802120141 f1 score: 0.7064220183486238 precision: 1.0 recall: 0.5460992907801419 confusion matrix: [[  1   0]\n",
      " [128 154]]\n",
      "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
      " [  0   2]]\n",
      "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
      " [  0   2]]\n",
      "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
      " [  0   2]]\n",
      "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
      " [  0   2]]\n",
      "accuracy: 0.5300353356890459 f1 score: 0.2887700534759358 precision: 0.17532467532467533 recall: 0.8181818181818182 confusion matrix: [[123 127]\n",
      " [  6  27]]\n",
      "accuracy: 0.5441696113074205 f1 score: 0.287292817679558 precision: 0.16883116883116883 recall: 0.9629629629629629 confusion matrix: [[128 128]\n",
      " [  1  26]]\n",
      "accuracy: 0.5300353356890459 f1 score: 0.24 precision: 0.13636363636363635 recall: 1.0 confusion matrix: [[129 133]\n",
      " [  0  21]]\n",
      "accuracy: 0.5406360424028268 f1 score: 0.29347826086956524 precision: 0.17532467532467533 recall: 0.9 confusion matrix: [[126 127]\n",
      " [  3  27]]\n",
      "accuracy: 0.5371024734982333 f1 score: 0.2994652406417112 precision: 0.18181818181818182 recall: 0.8484848484848485 confusion matrix: [[124 126]\n",
      " [  5  28]]\n",
      "accuracy: 0.5547703180212014 f1 score: 0.34375 precision: 0.21428571428571427 recall: 0.868421052631579 confusion matrix: [[124 121]\n",
      " [  5  33]]\n",
      "accuracy: 0.5335689045936396 f1 score: 0.2903225806451613 precision: 0.17532467532467533 recall: 0.84375 confusion matrix: [[124 127]\n",
      " [  5  27]]\n",
      "accuracy: 0.6855123674911661 f1 score: 0.6763636363636364 precision: 0.6038961038961039 recall: 0.768595041322314 confusion matrix: [[101  61]\n",
      " [ 28  93]]\n",
      "accuracy: 0.6325088339222615 f1 score: 0.543859649122807 precision: 0.4025974025974026 recall: 0.8378378378378378 confusion matrix: [[117  92]\n",
      " [ 12  62]]\n",
      "accuracy: 0.5406360424028268 f1 score: 0.30851063829787234 precision: 0.18831168831168832 recall: 0.8529411764705882 confusion matrix: [[124 125]\n",
      " [  5  29]]\n",
      "accuracy: 0.6219081272084805 f1 score: 0.5023255813953489 precision: 0.35064935064935066 recall: 0.8852459016393442 confusion matrix: [[122 100]\n",
      " [  7  54]]\n",
      "accuracy: 0.5441696113074205 f1 score: 0.287292817679558 precision: 0.16883116883116883 recall: 0.9629629629629629 confusion matrix: [[128 128]\n",
      " [  1  26]]\n",
      "accuracy: 0.519434628975265 f1 score: 0.21839080459770116 precision: 0.12337662337662338 recall: 0.95 confusion matrix: [[128 135]\n",
      " [  1  19]]\n",
      "accuracy: 0.5971731448763251 f1 score: 0.43 precision: 0.2792207792207792 recall: 0.9347826086956522 confusion matrix: [[126 111]\n",
      " [  3  43]]\n",
      "accuracy: 0.6501766784452296 f1 score: 0.5560538116591929 precision: 0.4025974025974026 recall: 0.8985507246376812 confusion matrix: [[122  92]\n",
      " [  7  62]]\n",
      "accuracy: 0.6007067137809188 f1 score: 0.43781094527363185 precision: 0.2857142857142857 recall: 0.9361702127659575 confusion matrix: [[126 110]\n",
      " [  3  44]]\n",
      "accuracy: 0.7667844522968198 f1 score: 0.7659574468085106 precision: 0.7012987012987013 recall: 0.84375 confusion matrix: [[109  46]\n",
      " [ 20 108]]\n",
      "accuracy: 0.6042402826855123 f1 score: 0.44554455445544555 precision: 0.2922077922077922 recall: 0.9375 confusion matrix: [[126 109]\n",
      " [  3  45]]\n",
      "accuracy: 0.5936395759717314 f1 score: 0.41624365482233505 precision: 0.2662337662337662 recall: 0.9534883720930233 confusion matrix: [[127 113]\n",
      " [  2  41]]\n",
      "accuracy: 0.6219081272084805 f1 score: 0.5023255813953489 precision: 0.35064935064935066 recall: 0.8852459016393442 confusion matrix: [[122 100]\n",
      " [  7  54]]\n",
      "accuracy: 0.6042402826855123 f1 score: 0.46153846153846156 precision: 0.3116883116883117 recall: 0.8888888888888888 confusion matrix: [[123 106]\n",
      " [  6  48]]\n",
      "accuracy: 0.6537102473498233 f1 score: 0.5585585585585585 precision: 0.4025974025974026 recall: 0.9117647058823529 confusion matrix: [[123  92]\n",
      " [  6  62]]\n",
      "accuracy: 0.6643109540636042 f1 score: 0.5777777777777777 precision: 0.42207792207792205 recall: 0.9154929577464789 confusion matrix: [[123  89]\n",
      " [  6  65]]\n",
      "accuracy: 0.5936395759717314 f1 score: 0.41624365482233505 precision: 0.2662337662337662 recall: 0.9534883720930233 confusion matrix: [[127 113]\n",
      " [  2  41]]\n",
      "accuracy: 0.5795053003533569 f1 score: 0.38341968911917096 precision: 0.24025974025974026 recall: 0.9487179487179487 confusion matrix: [[127 117]\n",
      " [  2  37]]\n",
      "accuracy: 0.5830388692579506 f1 score: 0.3917525773195876 precision: 0.24675324675324675 recall: 0.95 confusion matrix: [[127 116]\n",
      " [  2  38]]\n",
      "accuracy: 0.5795053003533569 f1 score: 0.38341968911917096 precision: 0.24025974025974026 recall: 0.9487179487179487 confusion matrix: [[127 117]\n",
      " [  2  37]]\n",
      "accuracy: 0.6395759717314488 f1 score: 0.5233644859813084 precision: 0.36363636363636365 recall: 0.9333333333333333 confusion matrix: [[125  98]\n",
      " [  4  56]]\n",
      "accuracy: 0.5971731448763251 f1 score: 0.42424242424242425 precision: 0.2727272727272727 recall: 0.9545454545454546 confusion matrix: [[127 112]\n",
      " [  2  42]]\n",
      "accuracy: 0.6537102473498233 f1 score: 0.5504587155963303 precision: 0.38961038961038963 recall: 0.9375 confusion matrix: [[125  94]\n",
      " [  4  60]]\n",
      "accuracy: 0.6501766784452296 f1 score: 0.5714285714285714 precision: 0.42857142857142855 recall: 0.8571428571428571 confusion matrix: [[118  88]\n",
      " [ 11  66]]\n",
      "accuracy: 0.657243816254417 f1 score: 0.5726872246696035 precision: 0.42207792207792205 recall: 0.8904109589041096 confusion matrix: [[121  89]\n",
      " [  8  65]]\n",
      "accuracy: 0.6749116607773852 f1 score: 0.6134453781512605 precision: 0.474025974025974 recall: 0.8690476190476191 confusion matrix: [[118  81]\n",
      " [ 11  73]]\n",
      "accuracy: 0.7597173144876325 f1 score: 0.7384615384615385 precision: 0.6233766233766234 recall: 0.9056603773584906 confusion matrix: [[119  58]\n",
      " [ 10  96]]\n",
      "accuracy: 0.6713780918727915 f1 score: 0.6008583690987125 precision: 0.45454545454545453 recall: 0.8860759493670886 confusion matrix: [[120  84]\n",
      " [  9  70]]\n",
      "accuracy: 0.6501766784452296 f1 score: 0.5638766519823789 precision: 0.4155844155844156 recall: 0.8767123287671232 confusion matrix: [[120  90]\n",
      " [  9  64]]\n",
      "accuracy: 0.607773851590106 f1 score: 0.4585365853658537 precision: 0.3051948051948052 recall: 0.9215686274509803 confusion matrix: [[125 107]\n",
      " [  4  47]]\n",
      "accuracy: 0.7597173144876325 f1 score: 0.746268656716418 precision: 0.6493506493506493 recall: 0.8771929824561403 confusion matrix: [[115  54]\n",
      " [ 14 100]]\n",
      "accuracy: 0.7385159010600707 f1 score: 0.7873563218390804 precision: 0.8896103896103896 recall: 0.7061855670103093 confusion matrix: [[ 72  17]\n",
      " [ 57 137]]\n",
      "accuracy: 0.6607773851590106 f1 score: 0.6 precision: 0.4675324675324675 recall: 0.8372093023255814 confusion matrix: [[115  82]\n",
      " [ 14  72]]\n",
      "accuracy: 0.607773851590106 f1 score: 0.4931506849315068 precision: 0.35064935064935066 recall: 0.8307692307692308 confusion matrix: [[118 100]\n",
      " [ 11  54]]\n",
      "accuracy: 0.5830388692579506 f1 score: 0.4215686274509804 precision: 0.2792207792207792 recall: 0.86 confusion matrix: [[122 111]\n",
      " [  7  43]]\n",
      "accuracy: 0.6501766784452296 f1 score: 0.5560538116591929 precision: 0.4025974025974026 recall: 0.8985507246376812 confusion matrix: [[122  92]\n",
      " [  7  62]]\n",
      "accuracy: 0.6749116607773852 f1 score: 0.6377952755905512 precision: 0.525974025974026 recall: 0.81 confusion matrix: [[110  73]\n",
      " [ 19  81]]\n",
      "accuracy: 0.6996466431095406 f1 score: 0.6743295019157088 precision: 0.5714285714285714 recall: 0.822429906542056 confusion matrix: [[110  66]\n",
      " [ 19  88]]\n",
      "accuracy: 0.7773851590106007 f1 score: 0.7725631768953068 precision: 0.6948051948051948 recall: 0.8699186991869918 confusion matrix: [[113  47]\n",
      " [ 16 107]]\n",
      "accuracy: 0.6607773851590106 f1 score: 0.6 precision: 0.4675324675324675 recall: 0.8372093023255814 confusion matrix: [[115  82]\n",
      " [ 14  72]]\n",
      "accuracy: 0.6890459363957597 f1 score: 0.6451612903225806 precision: 0.5194805194805194 recall: 0.851063829787234 confusion matrix: [[115  74]\n",
      " [ 14  80]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     out \u001b[38;5;241m=\u001b[39m final_model(X, A)\n\u001b[1;32m     10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(out, y)\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     13\u001b[0m print_acc(final_model, test_iter)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dyn_graph/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dyn_graph/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_model = EEGModel(num_nodes=19, node_features=51, num_classes=2, num_windows=50, device=DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.Tensor([10.0, 1.0]))\n",
    "optimizer = torch.optim.Adam(final_model.parameters(),lr=1e-3)\n",
    "final_model.train()\n",
    "for epoch in range(100): \n",
    "    final_model.train()\n",
    "    for idx, (X, A, y) in enumerate(train_iter):\n",
    "        optimizer.zero_grad()\n",
    "        out = final_model(X, A)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print_acc(final_model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afca0fd3-7803-43e1-a604-60c6ceb8ff29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f2e8824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson\n",
      "read_data\n",
      "(1758, 50, 19, 100) (280, 50, 19, 100)\n",
      "calculating connectivity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 0%|                                                  | 0/1758 [00:04<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(conn)    \n\u001b[1;32m      7\u001b[0m DEVICE \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m#torch.device(\"mps\")\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m train_iter, test_iter \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_X\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mtest_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_X\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mtest_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mcal_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[1;32m     15\u001b[0m final_model \u001b[38;5;241m=\u001b[39m EEGModel(num_nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m19\u001b[39m, node_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m63\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, num_windows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, device\u001b[38;5;241m=\u001b[39mDEVICE)\n\u001b[1;32m     16\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "Cell \u001b[0;32mIn[40], line 35\u001b[0m, in \u001b[0;36mtrain_test\u001b[0;34m(train_X, test_X, train_y, test_y, cal_conn, device, use_test_windows)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_X\u001b[38;5;241m.\u001b[39mshape, test_X\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 35\u001b[0m train_X, train_graphs, train_y \u001b[38;5;241m=\u001b[39m \u001b[43mgen_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcal_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcal_conn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m test_X, test_graphs, test_y \u001b[38;5;241m=\u001b[39m gen_features(test_X, test_y, device, cal_conn\u001b[38;5;241m=\u001b[39mcal_conn, \n\u001b[1;32m     38\u001b[0m                                            window_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90\u001b[39m, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#train_X, test_X = standardize_data(train_X, test_X)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[38], line 138\u001b[0m, in \u001b[0;36mgen_features\u001b[0;34m(X, y, device, cal_conn, window_size, overlap, augment, stft)\u001b[0m\n\u001b[1;32m    136\u001b[0m temp \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dynamic_range):\n\u001b[0;32m--> 138\u001b[0m     temp_g \u001b[38;5;241m=\u001b[39m \u001b[43mgen_graphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcal_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcal_conn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     temp_g \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(temp_g)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m#temp_g = (temp_g - temp_g.min())/(temp_g.max() - temp_g.min())\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m#temp_g[temp_g<threshold] = 0\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m#temp_g = csgraph.laplacian(temp_g)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[38], line 104\u001b[0m, in \u001b[0;36mgen_graphs\u001b[0;34m(eegs, num_nodes, cal_conn)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_nodes):\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cal_conn \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 104\u001b[0m         conn \u001b[38;5;241m=\u001b[39m \u001b[43mpearsonr\u001b[49m\u001b[43m(\u001b[49m\u001b[43meegs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meegs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m cal_conn \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    106\u001b[0m         conn \u001b[38;5;241m=\u001b[39m calculate_cc(eegs, i, j)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dyn_graph/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4817\u001b[0m, in \u001b[0;36mpearsonr\u001b[0;34m(x, y, alternative, method)\u001b[0m\n\u001b[1;32m   4814\u001b[0m \u001b[38;5;66;03m# As explained in the docstring, the distribution of `r` under the null\u001b[39;00m\n\u001b[1;32m   4815\u001b[0m \u001b[38;5;66;03m# hypothesis is the beta distribution on (-1, 1) with a = b = n/2 - 1.\u001b[39;00m\n\u001b[1;32m   4816\u001b[0m ab \u001b[38;5;241m=\u001b[39m n\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 4817\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alternative \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtwo-sided\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   4819\u001b[0m     prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mdist\u001b[38;5;241m.\u001b[39msf(\u001b[38;5;28mabs\u001b[39m(r))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dyn_graph/lib/python3.10/site-packages/scipy/stats/_distn_infrastructure.py:851\u001b[0m, in \u001b[0;36mrv_generic.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m--> 851\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfreeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dyn_graph/lib/python3.10/site-packages/scipy/stats/_distn_infrastructure.py:846\u001b[0m, in \u001b[0;36mrv_generic.freeze\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Freeze the distribution for the given arguments.\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \n\u001b[1;32m    833\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    843\u001b[0m \n\u001b[1;32m    844\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, rv_continuous):\n\u001b[0;32m--> 846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrv_continuous_frozen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rv_discrete_frozen(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dyn_graph/lib/python3.10/site-packages/scipy/stats/_distn_infrastructure.py:465\u001b[0m, in \u001b[0;36mrv_frozen.__init__\u001b[0;34m(self, dist, *args, **kwds)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds \u001b[38;5;241m=\u001b[39m kwds\n\u001b[1;32m    464\u001b[0m \u001b[38;5;66;03m# create a new instance\u001b[39;00m\n\u001b[0;32m--> 465\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdist \u001b[38;5;241m=\u001b[39m \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_updated_ctor_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m shapes, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdist\u001b[38;5;241m.\u001b[39m_parse_args(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdist\u001b[38;5;241m.\u001b[39m_get_support(\u001b[38;5;241m*\u001b[39mshapes)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dyn_graph/lib/python3.10/site-packages/scipy/stats/_distn_infrastructure.py:1848\u001b[0m, in \u001b[0;36mrv_continuous.__init__\u001b[0;34m(self, momtype, a, b, xtol, badvalue, name, longname, shapes, seed)\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1847\u001b[0m     dct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(distcont)\n\u001b[0;32m-> 1848\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocdict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dyn_graph/lib/python3.10/site-packages/scipy/stats/_distn_infrastructure.py:812\u001b[0m, in \u001b[0;36mrv_generic._construct_doc\u001b[0;34m(self, docdict, shapes_vals)\u001b[0m\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%(shapes)s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mdoccer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__doc__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtempdict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to construct docstring for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    815\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistribution \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dyn_graph/lib/python3.10/site-packages/scipy/_lib/doccer.py:61\u001b[0m, in \u001b[0;36mdocformat\u001b[0;34m(docstring, docdict)\u001b[0m\n\u001b[1;32m     59\u001b[0m indented \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, dstr \u001b[38;5;129;01min\u001b[39;00m docdict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 61\u001b[0m     lines \u001b[38;5;241m=\u001b[39m \u001b[43mdstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpandtabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m         newlines \u001b[38;5;241m=\u001b[39m [lines[\u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "conn_types = [\"pearson\", \"plv\", \"kld-entropy\", \"mi\"]\n",
    "num_epochs = 80\n",
    "results = {}\n",
    "    \n",
    "for conn in conn_types:\n",
    "    print(conn)    \n",
    "    DEVICE = torch.device(\"cpu\") #torch.device(\"mps\")\n",
    "    train_iter, test_iter = train_test(train_X=train_X[:, :50], \n",
    "                                       test_X=test_X[:, :50], \n",
    "                                       train_y=train_y, \n",
    "                                       test_y=test_y, \n",
    "                                       cal_conn=conn,\n",
    "                                       device=DEVICE)    \n",
    "    \n",
    "    final_model = EEGModel(num_nodes=19, node_features=63, num_classes=2, num_windows=50, device=DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(final_model.parameters(),lr=1e-3)\n",
    "    model = train_model(final_model, num_epochs, train_iter)\n",
    "    results[conn] = print_acc(model, test_iter)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e1eba63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson': [0.6882591093117408,\n",
       "  0.7158671586715867,\n",
       "  0.7698412698412699,\n",
       "  0.6689655172413793,\n",
       "  array([[73, 29],\n",
       "         [48, 97]])],\n",
       " 'plv': [0.6356275303643725,\n",
       "  0.7204968944099379,\n",
       "  0.9206349206349206,\n",
       "  0.5918367346938775,\n",
       "  array([[ 41,  10],\n",
       "         [ 80, 116]])]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "794f85af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5141700404858299 f1 score: 0.6774193548387097 precision: 1.0 recall: 0.5121951219512195 confusion matrix: [[  1   0]\n",
      " [120 126]]\n",
      "accuracy: 0.5101214574898786 f1 score: 0.675603217158177 precision: 1.0 recall: 0.5101214574898786 confusion matrix: [[  0   0]\n",
      " [121 126]]\n",
      "accuracy: 0.5101214574898786 f1 score: 0.675603217158177 precision: 1.0 recall: 0.5101214574898786 confusion matrix: [[  0   0]\n",
      " [121 126]]\n",
      "accuracy: 0.5870445344129555 f1 score: 0.7102272727272726 precision: 0.9920634920634921 recall: 0.5530973451327433 confusion matrix: [[ 20   1]\n",
      " [101 125]]\n",
      "accuracy: 0.5101214574898786 f1 score: 0.675603217158177 precision: 1.0 recall: 0.5101214574898786 confusion matrix: [[  0   0]\n",
      " [121 126]]\n",
      "accuracy: 0.7004048582995951 f1 score: 0.7658227848101266 precision: 0.9603174603174603 recall: 0.6368421052631579 confusion matrix: [[ 52   5]\n",
      " [ 69 121]]\n",
      "accuracy: 0.7206477732793523 f1 score: 0.7752442996742671 precision: 0.9444444444444444 recall: 0.6574585635359116 confusion matrix: [[ 59   7]\n",
      " [ 62 119]]\n",
      "accuracy: 0.631578947368421 f1 score: 0.7283582089552239 precision: 0.9682539682539683 recall: 0.583732057416268 confusion matrix: [[ 34   4]\n",
      " [ 87 122]]\n",
      "accuracy: 0.5910931174089069 f1 score: 0.7106017191977079 precision: 0.9841269841269841 recall: 0.5560538116591929 confusion matrix: [[ 22   2]\n",
      " [ 99 124]]\n",
      "accuracy: 0.7165991902834008 f1 score: 0.7651006711409396 precision: 0.9047619047619048 recall: 0.6627906976744186 confusion matrix: [[ 63  12]\n",
      " [ 58 114]]\n",
      "accuracy: 0.7125506072874493 f1 score: 0.7746031746031745 precision: 0.9682539682539683 recall: 0.6455026455026455 confusion matrix: [[ 54   4]\n",
      " [ 67 122]]\n",
      "accuracy: 0.7044534412955465 f1 score: 0.7667731629392971 precision: 0.9523809523809523 recall: 0.6417112299465241 confusion matrix: [[ 54   6]\n",
      " [ 67 120]]\n",
      "accuracy: 0.6072874493927125 f1 score: 0.718840579710145 precision: 0.9841269841269841 recall: 0.5662100456621004 confusion matrix: [[ 26   2]\n",
      " [ 95 124]]\n",
      "accuracy: 0.6518218623481782 f1 score: 0.7409638554216866 precision: 0.9761904761904762 recall: 0.5970873786407767 confusion matrix: [[ 38   3]\n",
      " [ 83 123]]\n",
      "accuracy: 0.7165991902834008 f1 score: 0.7727272727272727 precision: 0.9444444444444444 recall: 0.6538461538461539 confusion matrix: [[ 58   7]\n",
      " [ 63 119]]\n",
      "accuracy: 0.6356275303643725 f1 score: 0.7305389221556886 precision: 0.9682539682539683 recall: 0.5865384615384616 confusion matrix: [[ 35   4]\n",
      " [ 86 122]]\n",
      "accuracy: 0.6923076923076923 f1 score: 0.7610062893081762 precision: 0.9603174603174603 recall: 0.6302083333333334 confusion matrix: [[ 50   5]\n",
      " [ 71 121]]\n",
      "accuracy: 0.6356275303643725 f1 score: 0.7321428571428572 precision: 0.9761904761904762 recall: 0.5857142857142857 confusion matrix: [[ 34   3]\n",
      " [ 87 123]]\n",
      "accuracy: 0.708502024291498 f1 score: 0.7692307692307692 precision: 0.9523809523809523 recall: 0.6451612903225806 confusion matrix: [[ 55   6]\n",
      " [ 66 120]]\n",
      "accuracy: 0.659919028340081 f1 score: 0.7439024390243902 precision: 0.9682539682539683 recall: 0.6039603960396039 confusion matrix: [[ 41   4]\n",
      " [ 80 122]]\n",
      "accuracy: 0.7206477732793523 f1 score: 0.7781350482315111 precision: 0.9603174603174603 recall: 0.654054054054054 confusion matrix: [[ 57   5]\n",
      " [ 64 121]]\n",
      "accuracy: 0.7004048582995951 f1 score: 0.7597402597402597 precision: 0.9285714285714286 recall: 0.6428571428571429 confusion matrix: [[ 56   9]\n",
      " [ 65 117]]\n",
      "accuracy: 0.6923076923076923 f1 score: 0.7610062893081762 precision: 0.9603174603174603 recall: 0.6302083333333334 confusion matrix: [[ 50   5]\n",
      " [ 71 121]]\n",
      "accuracy: 0.6639676113360324 f1 score: 0.7477203647416413 precision: 0.9761904761904762 recall: 0.6059113300492611 confusion matrix: [[ 41   3]\n",
      " [ 80 123]]\n",
      "accuracy: 0.6720647773279352 f1 score: 0.7507692307692309 precision: 0.9682539682539683 recall: 0.6130653266331658 confusion matrix: [[ 44   4]\n",
      " [ 77 122]]\n",
      "accuracy: 0.6963562753036437 f1 score: 0.7457627118644067 precision: 0.873015873015873 recall: 0.650887573964497 confusion matrix: [[ 62  16]\n",
      " [ 59 110]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [55], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(final_model\u001b[38;5;241m.\u001b[39mparameters(),lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [53], line 42\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, num_epochs, data_iter)\u001b[0m\n\u001b[1;32m     40\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     41\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 42\u001b[0m     \u001b[43mprint_acc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "Cell \u001b[0;32mIn [53], line 10\u001b[0m, in \u001b[0;36mprint_acc\u001b[0;34m(model, data_iter)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X, A, y \u001b[38;5;129;01min\u001b[39;00m data_iter:\n\u001b[0;32m---> 10\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m         outs\u001b[38;5;241m.\u001b[39mextend(out\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     12\u001b[0m         ys\u001b[38;5;241m.\u001b[39mextend(y\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [42], line 279\u001b[0m, in \u001b[0;36mEEGModel.forward\u001b[0;34m(self, X, A)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, A):\n\u001b[0;32m--> 279\u001b[0m     HS1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforwardA3TGCN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m     X_flip \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflip(X, dims\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    281\u001b[0m     A_flip \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflip(A, dims\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [42], line 259\u001b[0m, in \u001b[0;36mA3TGCN.forward\u001b[0;34m(self, X, A, H)\u001b[0m\n\u001b[1;32m    257\u001b[0m row, col \u001b[38;5;241m=\u001b[39m idx\n\u001b[1;32m    258\u001b[0m w \u001b[38;5;241m=\u001b[39m At[row, col]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(X\u001b[38;5;241m.\u001b[39mdevice)            \n\u001b[0;32m--> 259\u001b[0m temp_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_tgcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m temp_emb \u001b[38;5;241m=\u001b[39m temp_emb\u001b[38;5;241m.\u001b[39mreshape(batch_size, \u001b[38;5;241m19\u001b[39m, \u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m    262\u001b[0m H_accum \u001b[38;5;241m=\u001b[39m H_accum \u001b[38;5;241m+\u001b[39m probs[period] \u001b[38;5;241m*\u001b[39m temp_emb \u001b[38;5;66;03m#([32, 207, 32]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [42], line 176\u001b[0m, in \u001b[0;36mTGCN.forward\u001b[0;34m(self, X, edge_index, edge_weight, H)\u001b[0m\n\u001b[1;32m    174\u001b[0m R \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_reset_gate(X, edge_index, edge_weight, H)\n\u001b[1;32m    175\u001b[0m H_tilde \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_candidate_state(X, edge_index, edge_weight, H, R)\n\u001b[0;32m--> 176\u001b[0m H \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_hidden_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH_tilde\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m H\n",
      "Cell \u001b[0;32mIn [42], line 148\u001b[0m, in \u001b[0;36mTGCN._calculate_hidden_state\u001b[0;34m(self, Z, H, H_tilde)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_calculate_hidden_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, Z, H, H_tilde):\n\u001b[0;32m--> 148\u001b[0m     H \u001b[38;5;241m=\u001b[39m Z \u001b[38;5;241m*\u001b[39m H \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m) \u001b[38;5;241m*\u001b[39m H_tilde\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m H\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/_tensor.py:39\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f, assigned\u001b[38;5;241m=\u001b[39massigned)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhas_torch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_model = EEGModel(num_nodes=19, node_features=63, num_classes=2, num_windows=50, device=DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(final_model.parameters(),lr=1e-3)\n",
    "model = train_model(final_model, 100, train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e4dfd-154a-49d4-b21a-bab13d83f0de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d392a-911d-4708-807a-b79cbe0a479c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12751481-c509-4ce7-a647-8da7e732afca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1722, 100, 19, 125)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "667cd0a9-4a9b-4d5e-abcf-1c9f9184319d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1497"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_y.squeeze()).count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4d1b661-4e7e-4797-a145-28f060f057a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16902356902356902"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "251/1485"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a8526-853f-4f75-9d14-0212bfcf8eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb6fee6-4a4f-48fe-a636-472844a912ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy: 0.4690909090909091 f1 score: 0.02666666666666667 precision: 0.013513513513513514 recall: 1.0 confusion matrix: [[127 146]\n",
    " [  0   2]]\n",
    "accuracy: 0.4690909090909091 f1 score: 0.02666666666666667 precision: 0.013513513513513514 recall: 1.0 confusion matrix: [[127 146]\n",
    " [  0   2]]\n",
    "accuracy: 0.4690909090909091 f1 score: 0.02666666666666667 precision: 0.013513513513513514 recall: 1.0 confusion matrix: [[127 146]\n",
    " [  0   2]]\n",
    "accuracy: 0.4690909090909091 f1 score: 0.02666666666666667 precision: 0.013513513513513514 recall: 1.0 confusion matrix: [[127 146]\n",
    " [  0   2]]\n",
    "accuracy: 0.4690909090909091 f1 score: 0.02666666666666667 precision: 0.013513513513513514 recall: 1.0 confusion matrix: [[127 146]\n",
    " [  0   2]]\n",
    "accuracy: 0.4763636363636364 f1 score: 0.06493506493506493 precision: 0.033783783783783786 recall: 0.8333333333333334 confusion matrix: [[126 143]\n",
    " [  1   5]]\n",
    "accuracy: 0.4690909090909091 f1 score: 0.02666666666666667 precision: 0.013513513513513514 recall: 1.0 confusion matrix: [[127 146]\n",
    " [  0   2]]\n",
    "accuracy: 0.4690909090909091 f1 score: 0.02666666666666667 precision: 0.013513513513513514 recall: 1.0 confusion matrix: [[127 146]\n",
    " [  0   2]]\n",
    "accuracy: 0.5527272727272727 f1 score: 0.32786885245901637 precision: 0.20270270270270271 recall: 0.8571428571428571 confusion matrix: [[122 118]\n",
    " [  5  30]]\n",
    "accuracy: 0.4690909090909091 f1 score: 0.02666666666666667 precision: 0.013513513513513514 recall: 1.0 confusion matrix: [[127 146]\n",
    " [  0   2]]\n",
    "accuracy: 0.5236363636363637 f1 score: 0.20606060606060606 precision: 0.11486486486486487 recall: 1.0 confusion matrix: [[127 131]\n",
    " [  0  17]]\n",
    "accuracy: 0.5890909090909091 f1 score: 0.4263959390862944 precision: 0.28378378378378377 recall: 0.8571428571428571 confusion matrix: [[120 106]\n",
    " [  7  42]]\n",
    "accuracy: 0.5309090909090909 f1 score: 0.27932960893854747 precision: 0.16891891891891891 recall: 0.8064516129032258 confusion matrix: [[121 123]\n",
    " [  6  25]]\n",
    "accuracy: 0.5418181818181819 f1 score: 0.31521739130434784 precision: 0.19594594594594594 recall: 0.8055555555555556 confusion matrix: [[120 119]\n",
    " [  7  29]]\n",
    "accuracy: 0.5418181818181819 f1 score: 0.26744186046511625 precision: 0.1554054054054054 recall: 0.9583333333333334 confusion matrix: [[126 125]\n",
    " [  1  23]]\n",
    "accuracy: 0.56 f1 score: 0.35978835978835977 precision: 0.22972972972972974 recall: 0.8292682926829268 confusion matrix: [[120 114]\n",
    " [  7  34]]\n",
    "accuracy: 0.5418181818181819 f1 score: 0.27586206896551724 precision: 0.16216216216216217 recall: 0.9230769230769231 confusion matrix: [[125 124]\n",
    " [  2  24]]\n",
    "accuracy: 0.6509090909090909 f1 score: 0.5555555555555556 precision: 0.40540540540540543 recall: 0.8823529411764706 confusion matrix: [[119  88]\n",
    " [  8  60]]\n",
    "accuracy: 0.5418181818181819 f1 score: 0.26744186046511625 precision: 0.1554054054054054 recall: 0.9583333333333334 confusion matrix: [[126 125]\n",
    " [  1  23]]\n",
    "accuracy: 0.5563636363636364 f1 score: 0.33695652173913043 precision: 0.20945945945945946 recall: 0.8611111111111112 confusion matrix: [[122 117]\n",
    " [  5  31]]\n",
    "accuracy: 0.5563636363636364 f1 score: 0.33695652173913043 precision: 0.20945945945945946 recall: 0.8611111111111112 confusion matrix: [[122 117]\n",
    " [  5  31]]\n",
    "accuracy: 0.6 f1 score: 0.4387755102040816 precision: 0.2905405405405405 recall: 0.8958333333333334 confusion matrix: [[122 105]\n",
    " [  5  43]]\n",
    "accuracy: 0.5381818181818182 f1 score: 0.2658959537572254 precision: 0.1554054054054054 recall: 0.92 confusion matrix: [[125 125]\n",
    " [  2  23]]\n",
    "accuracy: 0.6254545454545455 f1 score: 0.4975609756097561 precision: 0.34459459459459457 recall: 0.8947368421052632 confusion matrix: [[121  97]\n",
    " [  6  51]]\n",
    "accuracy: 0.7345454545454545 f1 score: 0.7068273092369478 precision: 0.5945945945945946 recall: 0.8712871287128713 confusion matrix: [[114  60]\n",
    " [ 13  88]]\n",
    "accuracy: 0.5381818181818182 f1 score: 0.2658959537572254 precision: 0.1554054054054054 recall: 0.92 confusion matrix: [[125 125]\n",
    " [  2  23]]\n",
    "accuracy: 0.7163636363636363 f1 score: 0.6776859504132231 precision: 0.5540540540540541 recall: 0.8723404255319149 confusion matrix: [[115  66]\n",
    " [ 12  82]]\n",
    "accuracy: 0.7818181818181819 f1 score: 0.782608695652174 precision: 0.7297297297297297 recall: 0.84375 confusion matrix: [[107  40]\n",
    " [ 20 108]]\n",
    "accuracy: 0.6436363636363637 f1 score: 0.5242718446601942 precision: 0.36486486486486486 recall: 0.9310344827586207 confusion matrix: [[123  94]\n",
    " [  4  54]]\n",
    "accuracy: 0.5490909090909091 f1 score: 0.29545454545454547 precision: 0.17567567567567569 recall: 0.9285714285714286 confusion matrix: [[125 122]\n",
    " [  2  26]]\n",
    "accuracy: 0.7890909090909091 f1 score: 0.8104575163398693 precision: 0.8378378378378378 recall: 0.7848101265822784 confusion matrix: [[ 93  24]\n",
    " [ 34 124]]\n",
    "accuracy: 0.6618181818181819 f1 score: 0.5592417061611374 precision: 0.39864864864864863 recall: 0.9365079365079365 confusion matrix: [[123  89]\n",
    " [  4  59]]\n",
    "accuracy: 0.7236363636363636 f1 score: 0.6724137931034483 precision: 0.527027027027027 recall: 0.9285714285714286 confusion matrix: [[121  70]\n",
    " [  6  78]]\n",
    "accuracy: 0.6436363636363637 f1 score: 0.5196078431372549 precision: 0.3581081081081081 recall: 0.9464285714285714 confusion matrix: [[124  95]\n",
    " [  3  53]]\n",
    "accuracy: 0.5745454545454546 f1 score: 0.36065573770491804 precision: 0.22297297297297297 recall: 0.9428571428571428 confusion matrix: [[125 115]\n",
    " [  2  33]]\n",
    "accuracy: 0.5927272727272728 f1 score: 0.4105263157894737 precision: 0.2635135135135135 recall: 0.9285714285714286 confusion matrix: [[124 109]\n",
    " [  3  39]]\n",
    "accuracy: 0.8036363636363636 f1 score: 0.8187919463087249 precision: 0.8243243243243243 recall: 0.8133333333333334 confusion matrix: [[ 99  26]\n",
    " [ 28 122]]\n",
    "accuracy: 0.5890909090909091 f1 score: 0.39572192513368987 precision: 0.25 recall: 0.9487179487179487 confusion matrix: [[125 111]\n",
    " [  2  37]]\n",
    "accuracy: 0.6763636363636364 f1 score: 0.5898617511520737 precision: 0.43243243243243246 recall: 0.927536231884058 confusion matrix: [[122  84]\n",
    " [  5  64]]\n",
    "accuracy: 0.5927272727272728 f1 score: 0.40425531914893614 precision: 0.25675675675675674 recall: 0.95 confusion matrix: [[125 110]\n",
    " [  2  38]]\n",
    "accuracy: 0.5854545454545454 f1 score: 0.3870967741935484 precision: 0.24324324324324326 recall: 0.9473684210526315 confusion matrix: [[125 112]\n",
    " [  2  36]]\n",
    "accuracy: 0.7236363636363636 f1 score: 0.6859504132231405 precision: 0.5608108108108109 recall: 0.8829787234042553 confusion matrix: [[116  65]\n",
    " [ 11  83]]\n",
    "accuracy: 0.7818181818181819 f1 score: 0.7794117647058824 precision: 0.7162162162162162 recall: 0.8548387096774194 confusion matrix: [[109  42]\n",
    " [ 18 106]]\n",
    "accuracy: 0.8072727272727273 f1 score: 0.8166089965397924 precision: 0.7972972972972973 recall: 0.8368794326241135 confusion matrix: [[104  30]\n",
    " [ 23 118]]\n",
    "accuracy: 0.72 f1 score: 0.6831275720164609 precision: 0.5608108108108109 recall: 0.8736842105263158 confusion matrix: [[115  65]\n",
    " [ 12  83]]\n",
    "accuracy: 0.6 f1 score: 0.4329896907216495 precision: 0.28378378378378377 recall: 0.9130434782608695 confusion matrix: [[123 106]\n",
    " [  4  42]]\n",
    "accuracy: 0.6 f1 score: 0.4329896907216495 precision: 0.28378378378378377 recall: 0.9130434782608695 confusion matrix: [[123 106]\n",
    " [  4  42]]\n",
    "accuracy: 0.76 f1 score: 0.7421875 precision: 0.6418918918918919 recall: 0.8796296296296297 confusion matrix: [[114  53]\n",
    " [ 13  95]]\n",
    "accuracy: 0.7636363636363637 f1 score: 0.7547169811320755 precision: 0.6756756756756757 recall: 0.8547008547008547 confusion matrix: [[110  48]\n",
    " [ 17 100]]\n",
    "accuracy: 0.7927272727272727 f1 score: 0.7956989247311828 precision: 0.75 recall: 0.8473282442748091 confusion matrix: [[107  37]\n",
    " [ 20 111]]\n",
    "accuracy: 0.6836363636363636 f1 score: 0.6167400881057269 precision: 0.47297297297297297 recall: 0.8860759493670886 confusion matrix: [[118  78]\n",
    " [  9  70]]\n",
    "accuracy: 0.7490909090909091 f1 score: 0.7335907335907336 precision: 0.6418918918918919 recall: 0.8558558558558559 confusion matrix: [[111  53]\n",
    " [ 16  95]]\n",
    "accuracy: 0.7018181818181818 f1 score: 0.6583333333333333 precision: 0.5337837837837838 recall: 0.8586956521739131 confusion matrix: [[114  69]\n",
    " [ 13  79]]\n",
    "accuracy: 0.7963636363636364 f1 score: 0.8 precision: 0.7567567567567568 recall: 0.8484848484848485 confusion matrix: [[107  36]\n",
    " [ 20 112]]\n",
    "accuracy: 0.6654545454545454 f1 score: 0.5892857142857143 precision: 0.44594594594594594 recall: 0.868421052631579 confusion matrix: [[117  82]\n",
    " [ 10  66]]\n",
    "accuracy: 0.6545454545454545 f1 score: 0.5581395348837209 precision: 0.40540540540540543 recall: 0.8955223880597015 confusion matrix: [[120  88]\n",
    " [  7  60]]\n",
    "accuracy: 0.7454545454545455 f1 score: 0.7865853658536586 precision: 0.8716216216216216 recall: 0.7166666666666667 confusion matrix: [[ 76  19]\n",
    " [ 51 129]]\n",
    "accuracy: 0.7781818181818182 f1 score: 0.779783393501805 precision: 0.7297297297297297 recall: 0.8372093023255814 confusion matrix: [[106  40]\n",
    " [ 21 108]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacc2074-93dc-4704-8585-f9c2acf076f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
    " [  0   2]]\n",
    "accuracy: 0.4416961130742049 f1 score: 0.07058823529411765 precision: 0.03896103896103896 recall: 0.375 confusion matrix: [[119 148]\n",
    " [ 10   6]]\n",
    "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
    " [  0   2]]\n",
    "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
    " [  0   2]]\n",
    "accuracy: 0.5477031802120141 f1 score: 0.7064220183486238 precision: 1.0 recall: 0.5460992907801419 confusion matrix: [[  1   0]\n",
    " [128 154]]\n",
    "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
    " [  0   2]]\n",
    "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
    " [  0   2]]\n",
    "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
    " [  0   2]]\n",
    "accuracy: 0.5053003533568905 f1 score: 0.3 precision: 0.19480519480519481 recall: 0.6521739130434783 confusion matrix: [[113 124]\n",
    " [ 16  30]]\n",
    "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
    " [  0   2]]\n",
    "accuracy: 0.519434628975265 f1 score: 0.30612244897959184 precision: 0.19480519480519481 recall: 0.7142857142857143 confusion matrix: [[117 124]\n",
    " [ 12  30]]\n",
    "accuracy: 0.45936395759717313 f1 score: 0.025477707006369428 precision: 0.012987012987012988 recall: 0.6666666666666666 confusion matrix: [[128 152]\n",
    " [  1   2]]\n",
    "accuracy: 0.5159010600706714 f1 score: 0.29743589743589743 precision: 0.18831168831168832 recall: 0.7073170731707317 confusion matrix: [[117 125]\n",
    " [ 12  29]]\n",
    "accuracy: 0.5335689045936396 f1 score: 0.2903225806451613 precision: 0.17532467532467533 recall: 0.84375 confusion matrix: [[124 127]\n",
    " [  5  27]]\n",
    "accuracy: 0.4628975265017668 f1 score: 0.02564102564102564 precision: 0.012987012987012988 recall: 1.0 confusion matrix: [[129 152]\n",
    " [  0   2]]\n",
    "accuracy: 0.45936395759717313 f1 score: 0.025477707006369428 precision: 0.012987012987012988 recall: 0.6666666666666666 confusion matrix: [[128 152]\n",
    " [  1   2]]\n",
    "accuracy: 0.519434628975265 f1 score: 0.22727272727272727 precision: 0.12987012987012986 recall: 0.9090909090909091 confusion matrix: [[127 134]\n",
    " [  2  20]]\n",
    "accuracy: 0.5123674911660777 f1 score: 0.20689655172413793 precision: 0.11688311688311688 recall: 0.9 confusion matrix: [[127 136]\n",
    " [  2  18]]\n",
    "accuracy: 0.5371024734982333 f1 score: 0.2994652406417112 precision: 0.18181818181818182 recall: 0.8484848484848485 confusion matrix: [[124 126]\n",
    " [  5  28]]\n",
    "accuracy: 0.568904593639576 f1 score: 0.46956521739130436 precision: 0.35064935064935066 recall: 0.7105263157894737 confusion matrix: [[107 100]\n",
    " [ 22  54]]\n",
    "accuracy: 0.558303886925795 f1 score: 0.37185929648241206 precision: 0.24025974025974026 recall: 0.8222222222222222 confusion matrix: [[121 117]\n",
    " [  8  37]]\n",
    "accuracy: 0.5441696113074205 f1 score: 0.3027027027027027 precision: 0.18181818181818182 recall: 0.9032258064516129 confusion matrix: [[126 126]\n",
    " [  3  28]]\n",
    "accuracy: 0.5547703180212014 f1 score: 0.36363636363636365 precision: 0.23376623376623376 recall: 0.8181818181818182 confusion matrix: [[121 118]\n",
    " [  8  36]]\n",
    "accuracy: 0.5406360424028268 f1 score: 0.3157894736842105 precision: 0.19480519480519481 recall: 0.8333333333333334 confusion matrix: [[123 124]\n",
    " [  6  30]]\n",
    "accuracy: 0.6219081272084805 f1 score: 0.5114155251141552 precision: 0.36363636363636365 recall: 0.8615384615384616 confusion matrix: [[120  98]\n",
    " [  9  56]]\n",
    "accuracy: 0.5441696113074205 f1 score: 0.29508196721311475 precision: 0.17532467532467533 recall: 0.9310344827586207 confusion matrix: [[127 127]\n",
    " [  2  27]]\n",
    "accuracy: 0.5512367491166078 f1 score: 0.31351351351351353 precision: 0.18831168831168832 recall: 0.9354838709677419 confusion matrix: [[127 125]\n",
    " [  2  29]]\n",
    "accuracy: 0.6855123674911661 f1 score: 0.6147186147186147 precision: 0.461038961038961 recall: 0.922077922077922 confusion matrix: [[123  83]\n",
    " [  6  71]]\n",
    "accuracy: 0.5971731448763251 f1 score: 0.42424242424242425 precision: 0.2727272727272727 recall: 0.9545454545454546 confusion matrix: [[127 112]\n",
    " [  2  42]]\n",
    "accuracy: 0.6007067137809188 f1 score: 0.4321608040201005 precision: 0.2792207792207792 recall: 0.9555555555555556 confusion matrix: [[127 111]\n",
    " [  2  43]]\n",
    "accuracy: 0.6183745583038869 f1 score: 0.47572815533980584 precision: 0.3181818181818182 recall: 0.9423076923076923 confusion matrix: [[126 105]\n",
    " [  3  49]]\n",
    "accuracy: 0.6148409893992933 f1 score: 0.4682926829268293 precision: 0.3116883116883117 recall: 0.9411764705882353 confusion matrix: [[126 106]\n",
    " [  3  48]]\n",
    "accuracy: 0.5971731448763251 f1 score: 0.42424242424242425 precision: 0.2727272727272727 recall: 0.9545454545454546 confusion matrix: [[127 112]\n",
    " [  2  42]]\n",
    "accuracy: 0.784452296819788 f1 score: 0.7813620071684588 precision: 0.7077922077922078 recall: 0.872 confusion matrix: [[113  45]\n",
    " [ 16 109]]\n",
    "accuracy: 0.8021201413427562 f1 score: 0.8145695364238411 precision: 0.7987012987012987 recall: 0.831081081081081 confusion matrix: [[104  31]\n",
    " [ 25 123]]\n",
    "accuracy: 0.7985865724381626 f1 score: 0.8054607508532423 precision: 0.7662337662337663 recall: 0.8489208633093526 confusion matrix: [[108  36]\n",
    " [ 21 118]]\n",
    "accuracy: 0.6537102473498233 f1 score: 0.5663716814159292 precision: 0.4155844155844156 recall: 0.8888888888888888 confusion matrix: [[121  90]\n",
    " [  8  64]]\n",
    "accuracy: 0.7703180212014135 f1 score: 0.7547169811320755 precision: 0.6493506493506493 recall: 0.9009009009009009 confusion matrix: [[118  54]\n",
    " [ 11 100]]\n",
    "accuracy: 0.6713780918727915 f1 score: 0.5829596412556054 precision: 0.42207792207792205 recall: 0.9420289855072463 confusion matrix: [[125  89]\n",
    " [  4  65]]\n",
    "accuracy: 0.6784452296819788 f1 score: 0.5955555555555555 precision: 0.43506493506493504 recall: 0.9436619718309859 confusion matrix: [[125  87]\n",
    " [  4  67]]\n",
    "accuracy: 0.5901060070671378 f1 score: 0.42 precision: 0.2727272727272727 recall: 0.9130434782608695 confusion matrix: [[125 112]\n",
    " [  4  42]]\n",
    "accuracy: 0.5901060070671378 f1 score: 0.40816326530612246 precision: 0.2597402597402597 recall: 0.9523809523809523 confusion matrix: [[127 114]\n",
    " [  2  40]]\n",
    "accuracy: 0.6607773851590106 f1 score: 0.5636363636363636 precision: 0.4025974025974026 recall: 0.9393939393939394 confusion matrix: [[125  92]\n",
    " [  4  62]]\n",
    "accuracy: 0.7561837455830389 f1 score: 0.7315175097276264 precision: 0.6103896103896104 recall: 0.912621359223301 confusion matrix: [[120  60]\n",
    " [  9  94]]\n",
    "accuracy: 0.6996466431095406 f1 score: 0.6443514644351465 precision: 0.5 recall: 0.9058823529411765 confusion matrix: [[121  77]\n",
    " [  8  77]]\n",
    "accuracy: 0.8197879858657244 f1 score: 0.8235294117647058 precision: 0.7727272727272727 recall: 0.8814814814814815 confusion matrix: [[113  35]\n",
    " [ 16 119]]\n",
    "accuracy: 0.6819787985865724 f1 score: 0.6153846153846154 precision: 0.4675324675324675 recall: 0.9 confusion matrix: [[121  82]\n",
    " [  8  72]]\n",
    "accuracy: 0.7067137809187279 f1 score: 0.6693227091633466 precision: 0.5454545454545454 recall: 0.865979381443299 confusion matrix: [[116  70]\n",
    " [ 13  84]]\n",
    "accuracy: 0.6501766784452296 f1 score: 0.547945205479452 precision: 0.38961038961038963 recall: 0.9230769230769231 confusion matrix: [[124  94]\n",
    " [  5  60]]\n",
    "accuracy: 0.6537102473498233 f1 score: 0.5504587155963303 precision: 0.38961038961038963 recall: 0.9375 confusion matrix: [[125  94]\n",
    " [  4  60]]\n",
    "accuracy: 0.7208480565371025 f1 score: 0.680161943319838 precision: 0.5454545454545454 recall: 0.9032258064516129 confusion matrix: [[120  70]\n",
    " [  9  84]]\n",
    "accuracy: 0.8056537102473498 f1 score: 0.8028673835125448 precision: 0.7272727272727273 recall: 0.896 confusion matrix: [[116  42]\n",
    " [ 13 112]]\n",
    "accuracy: 0.6360424028268551 f1 score: 0.5164319248826291 precision: 0.35714285714285715 recall: 0.9322033898305084 confusion matrix: [[125  99]\n",
    " [  4  55]]\n",
    "accuracy: 0.6643109540636042 f1 score: 0.5814977973568282 precision: 0.42857142857142855 recall: 0.9041095890410958 confusion matrix: [[122  88]\n",
    " [  7  66]]\n",
    "accuracy: 0.657243816254417 f1 score: 0.5650224215246636 precision: 0.4090909090909091 recall: 0.9130434782608695 confusion matrix: [[123  91]\n",
    " [  6  63]]\n",
    "accuracy: 0.6890459363957597 f1 score: 0.6302521008403361 precision: 0.487012987012987 recall: 0.8928571428571429 confusion matrix: [[120  79]\n",
    " [  9  75]]\n",
    "accuracy: 0.7950530035335689 f1 score: 0.7986111111111112 precision: 0.7467532467532467 recall: 0.8582089552238806 confusion matrix: [[110  39]\n",
    " [ 19 115]]\n",
    "accuracy: 0.7102473498233216 f1 score: 0.6796875 precision: 0.564935064935065 recall: 0.8529411764705882 confusion matrix: [[114  67]\n",
    " [ 15  87]]\n",
    "accuracy: 0.7208480565371025 f1 score: 0.680161943319838 precision: 0.5454545454545454 recall: 0.9032258064516129 confusion matrix: [[120  70]\n",
    " [  9  84]]\n",
    "accuracy: 0.7067137809187279 f1 score: 0.6527196652719666 precision: 0.5064935064935064 recall: 0.9176470588235294 confusion matrix: [[122  76]\n",
    " [  7  78]]\n",
    "accuracy: 0.7243816254416962 f1 score: 0.6829268292682927 precision: 0.5454545454545454 recall: 0.9130434782608695 confusion matrix: [[121  70]\n",
    " [  8  84]]\n",
    "accuracy: 0.6360424028268551 f1 score: 0.5209302325581395 precision: 0.36363636363636365 recall: 0.9180327868852459 confusion matrix: [[124  98]\n",
    " [  5  56]]\n",
    "accuracy: 0.607773851590106 f1 score: 0.44776119402985076 precision: 0.2922077922077922 recall: 0.9574468085106383 confusion matrix: [[127 109]\n",
    " [  2  45]]\n",
    "accuracy: 0.6678445229681979 f1 score: 0.584070796460177 precision: 0.42857142857142855 recall: 0.9166666666666666 confusion matrix: [[123  88]\n",
    " [  6  66]]\n",
    "accuracy: 0.657243816254417 f1 score: 0.5650224215246636 precision: 0.4090909090909091 recall: 0.9130434782608695 confusion matrix: [[123  91]\n",
    " [  6  63]]\n",
    "accuracy: 0.6819787985865724 f1 score: 0.6186440677966102 precision: 0.474025974025974 recall: 0.8902439024390244 confusion matrix: [[120  81]\n",
    " [  9  73]]\n",
    "accuracy: 0.6431095406360424 f1 score: 0.5429864253393665 precision: 0.38961038961038963 recall: 0.8955223880597015 confusion matrix: [[122  94]\n",
    " [  7  60]]\n",
    "accuracy: 0.5936395759717314 f1 score: 0.42786069651741293 precision: 0.2792207792207792 recall: 0.9148936170212766 confusion matrix: [[125 111]\n",
    " [  4  43]]\n",
    "accuracy: 0.6890459363957597 f1 score: 0.6206896551724138 precision: 0.4675324675324675 recall: 0.9230769230769231 confusion matrix: [[123  82]\n",
    " [  6  72]]\n",
    "accuracy: 0.6643109540636042 f1 score: 0.5739910313901345 precision: 0.4155844155844156 recall: 0.927536231884058 confusion matrix: [[124  90]\n",
    " [  5  64]]\n",
    "accuracy: 0.7632508833922261 f1 score: 0.7490636704119851 precision: 0.6493506493506493 recall: 0.8849557522123894 confusion matrix: [[116  54]\n",
    " [ 13 100]]\n",
    "accuracy: 0.7067137809187279 f1 score: 0.6527196652719666 precision: 0.5064935064935064 recall: 0.9176470588235294 confusion matrix: [[122  76]\n",
    " [  7  78]]\n",
    "accuracy: 0.6855123674911661 f1 score: 0.6244725738396625 precision: 0.4805194805194805 recall: 0.891566265060241 confusion matrix: [[120  80]\n",
    " [  9  74]]\n",
    "accuracy: 0.6607773851590106 f1 score: 0.5932203389830508 precision: 0.45454545454545453 recall: 0.8536585365853658 confusion matrix: [[117  84]\n",
    " [ 12  70]]\n",
    "accuracy: 0.6325088339222615 f1 score: 0.5229357798165137 precision: 0.37012987012987014 recall: 0.890625 confusion matrix: [[122  97]\n",
    " [  7  57]]\n",
    "accuracy: 0.7385159010600707 f1 score: 0.7153846153846154 precision: 0.6038961038961039 recall: 0.8773584905660378 confusion matrix: [[116  61]\n",
    " [ 13  93]]\n",
    "accuracy: 0.6678445229681979 f1 score: 0.5877192982456141 precision: 0.43506493506493504 recall: 0.9054054054054054 confusion matrix: [[122  87]\n",
    " [  7  67]]\n",
    "accuracy: 0.6607773851590106 f1 score: 0.5789473684210527 precision: 0.42857142857142855 recall: 0.8918918918918919 confusion matrix: [[121  88]\n",
    " [  8  66]]\n",
    "accuracy: 0.8021201413427562 f1 score: 0.8108108108108109 precision: 0.7792207792207793 recall: 0.8450704225352113 confusion matrix: [[107  34]\n",
    " [ 22 120]]\n",
    "accuracy: 0.7208480565371025 f1 score: 0.6926070038910506 precision: 0.577922077922078 recall: 0.8640776699029126 confusion matrix: [[115  65]\n",
    " [ 14  89]]\n",
    "accuracy: 0.7031802120141343 f1 score: 0.6440677966101694 precision: 0.4935064935064935 recall: 0.926829268292683 confusion matrix: [[123  78]\n",
    " [  6  76]]\n",
    "accuracy: 0.6855123674911661 f1 score: 0.6147186147186147 precision: 0.461038961038961 recall: 0.922077922077922 confusion matrix: [[123  83]\n",
    " [  6  71]]\n",
    "accuracy: 0.784452296819788 f1 score: 0.7765567765567766 precision: 0.6883116883116883 recall: 0.8907563025210085 confusion matrix: [[116  48]\n",
    " [ 13 106]]\n",
    "accuracy: 0.6607773851590106 f1 score: 0.5752212389380531 precision: 0.42207792207792205 recall: 0.9027777777777778 confusion matrix: [[122  89]\n",
    " [  7  65]]\n",
    "accuracy: 0.6678445229681979 f1 score: 0.6050420168067226 precision: 0.4675324675324675 recall: 0.8571428571428571 confusion matrix: [[117  82]\n",
    " [ 12  72]]\n",
    "accuracy: 0.7879858657243817 f1 score: 0.7945205479452054 precision: 0.7532467532467533 recall: 0.8405797101449275 confusion matrix: [[107  38]\n",
    " [ 22 116]]\n",
    "accuracy: 0.7950530035335689 f1 score: 0.795774647887324 precision: 0.7337662337662337 recall: 0.8692307692307693 confusion matrix: [[112  41]\n",
    " [ 17 113]]\n",
    "accuracy: 0.7137809187279152 f1 score: 0.6872586872586872 precision: 0.577922077922078 recall: 0.8476190476190476 confusion matrix: [[113  65]\n",
    " [ 16  89]]\n",
    "accuracy: 0.6678445229681979 f1 score: 0.5877192982456141 precision: 0.43506493506493504 recall: 0.9054054054054054 confusion matrix: [[122  87]\n",
    " [  7  67]]\n",
    "accuracy: 0.7137809187279152 f1 score: 0.6823529411764706 precision: 0.564935064935065 recall: 0.8613861386138614 confusion matrix: [[115  67]\n",
    " [ 14  87]]\n",
    "accuracy: 0.6996466431095406 f1 score: 0.6530612244897959 precision: 0.5194805194805194 recall: 0.8791208791208791 confusion matrix: [[118  74]\n",
    " [ 11  80]]\n",
    "accuracy: 0.6749116607773852 f1 score: 0.6101694915254238 precision: 0.4675324675324675 recall: 0.8780487804878049 confusion matrix: [[119  82]\n",
    " [ 10  72]]\n",
    "accuracy: 0.6678445229681979 f1 score: 0.5948275862068966 precision: 0.44805194805194803 recall: 0.8846153846153846 confusion matrix: [[120  85]\n",
    " [  9  69]]\n",
    "accuracy: 0.6925795053003534 f1 score: 0.6419753086419753 precision: 0.5064935064935064 recall: 0.8764044943820225 confusion matrix: [[118  76]\n",
    " [ 11  78]]\n",
    "accuracy: 0.7597173144876325 f1 score: 0.7424242424242424 precision: 0.6363636363636364 recall: 0.8909090909090909 confusion matrix: [[117  56]\n",
    " [ 12  98]]\n",
    "accuracy: 0.7137809187279152 f1 score: 0.6693877551020408 precision: 0.5324675324675324 recall: 0.9010989010989011 confusion matrix: [[120  72]\n",
    " [  9  82]]\n",
    "accuracy: 0.6431095406360424 f1 score: 0.5429864253393665 precision: 0.38961038961038963 recall: 0.8955223880597015 confusion matrix: [[122  94]\n",
    " [  7  60]]\n",
    "accuracy: 0.696113074204947 f1 score: 0.6446280991735537 precision: 0.5064935064935064 recall: 0.8863636363636364 confusion matrix: [[119  76]\n",
    " [ 10  78]]\n",
    "accuracy: 0.773851590106007 f1 score: 0.7681159420289855 precision: 0.6883116883116883 recall: 0.8688524590163934 confusion matrix: [[113  48]\n",
    " [ 16 106]]\n",
    "accuracy: 0.7420494699646644 f1 score: 0.7159533073929961 precision: 0.5974025974025974 recall: 0.8932038834951457 confusion matrix: [[118  62]\n",
    " [ 11  92]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
