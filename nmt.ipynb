{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ebf9827-f991-4b4c-a62b-1b8d6b0ed450",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2417\n",
      "2232 185\n",
      "plv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NMT Abnormal Dataset\n",
    "\"\"\"\n",
    "\n",
    "import glob, os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#from src.model import EEGModel\n",
    "from src.read_data import build_data\n",
    "from src.make_features import train_test\n",
    "#from src.train import train_model, print_acc\n",
    "\n",
    "def norm_adj(train_graphs, test_graphs):\n",
    "    for i in range(train_graphs.shape[0]):\n",
    "        for j in range(train_graphs.shape[1]):\n",
    "                min_ = (train_graphs[i, j, :, :]).min()\n",
    "                max_ = (train_graphs[i, j, :, :]).max()\n",
    "                train_graphs[i, j, :,  :] = (train_graphs[i, j, :,  :] - min_)/(max_ - min_)\n",
    "                \n",
    "    for i in range(test_graphs.shape[0]):\n",
    "        for j in range(test_graphs.shape[1]):\n",
    "            min_ = (test_graphs[i, j, :, :]).min()\n",
    "            max_ = (test_graphs[i, j, :, :]).max()\n",
    "            test_graphs[i, j, :, :] = (test_graphs[i, j, :,  :] - min_)/(max_ - min_)\n",
    "            \n",
    "    return train_graphs, test_graphs\n",
    "\n",
    "\n",
    "def norm_adj(train_graphs, test_graphs):\n",
    "    for i in range(train_graphs.shape[2]):\n",
    "        for j in range(train_graphs.shape[3]):\n",
    "            if train_graphs[:, :, i, j].sum != 0:\n",
    "                min_ = (train_graphs[:, :, i, j]).min()\n",
    "                max_ = (train_graphs[:, :, i, j]).max()\n",
    "                train_graphs[:, :, i,  j] = (train_graphs[:, :, i,  j] - min_)/(max_ - min_)\n",
    "                test_graphs[:, :, i, j] = (test_graphs[:, :, i,  j] - min_)/(max_ - min_)\n",
    "            if i == j:\n",
    "                train_graphs[:, :, i, j] = 1\n",
    "            \n",
    "    return train_graphs, test_graphs\n",
    "\n",
    "def norm_adj(train_graphs, test_graphs):\n",
    "    for i in range(train_graphs.shape[0]):\n",
    "        for j in range(train_graphs.shape[1]):\n",
    "                min_ = (train_graphs[i, j, :, :]).min()\n",
    "                max_ = (train_graphs[i, j, :, :]).max()\n",
    "                train_graphs[i, j, :,  :] = (train_graphs[i, j, :,  :] - min_)/(max_ - min_)\n",
    "                \n",
    "    for i in range(test_graphs.shape[0]):\n",
    "        for j in range(test_graphs.shape[1]):\n",
    "            min_ = (test_graphs[i, j, :, :]).min()\n",
    "            max_ = (test_graphs[i, j, :, :]).max()\n",
    "            test_graphs[i, j, :, :] = (test_graphs[i, j, :,  :] - min_)/(max_ - min_)\n",
    "            \n",
    "    return train_graphs, test_graphs\n",
    "    \n",
    "SAVED_DATA = True\n",
    "SAVED_FEATURES = True\n",
    "CONN_TYPES = [\"plv\"]#, \"ciplv\", \"coh\", \"pc\"]\n",
    "\n",
    "# Files names on disk\n",
    "files, train_files, test_files = [], [], []\n",
    "for file in glob.glob(\"/Users/mohamedr/projects/limited_data/graphs/bands/dynamic_graphs/nmt/*/*/*/*.edf\"):\n",
    "    files.append(file)\n",
    "    if \"train\" in file:\n",
    "        train_files.append(file)\n",
    "    else:\n",
    "        test_files.append(file)\n",
    "print(len(files))\n",
    "np.random.shuffle(train_files)\n",
    "print(len(train_files), len(test_files))\n",
    "\n",
    "for conn in CONN_TYPES:    \n",
    "    print(conn)\n",
    "    if SAVED_FEATURES:\n",
    "        train_X = np.load(\"../saved_npy_nmt/features/train_X.npy\") #samples, #epochs, #channels, #time points)\n",
    "        train_y = np.load(\"../saved_npy_nmt/features/train_y.npy\")\n",
    "        train_graphs = np.load(\"../saved_npy_nmt/features/train_graphs_\"+conn+\".npy\")\n",
    "        test_y = np.load(\"../saved_npy_nmt/features/test_y.npy\")\n",
    "        test_X = np.load(\"../saved_npy_nmt/features/test_X.npy\")\n",
    "        test_graphs = np.load(\"../saved_npy_nmt/features/test_graphs_\"+conn+\".npy\")\n",
    "        train_X = np.moveaxis(train_X, 1, -1)\n",
    "        test_X = np.moveaxis(test_X, 1, -1)\n",
    "        train_graphs, test_graphs = norm_adj(train_graphs, test_graphs)\n",
    "        #train_X, test_X = standardize_data(train_X, test_X)\n",
    "        \n",
    "    else:\n",
    "        if SAVED_DATA:\n",
    "            # Saved arrays on disk\n",
    "            train_X_files = [\"../saved_npy_nmt/features/train_X\"+str(i)+\".npy\" for i in range(0, len(train_files), 100)]\n",
    "            train_y_files = [\"../saved_npy_nmt/features/train_y\"+str(i)+\".npy\" for i in range(0, len(train_files), 100)]\n",
    "            train_X = np.vstack([np.load(file).astype(np.float16) for i, file in enumerate(train_X_files)])\n",
    "            train_y = np.vstack([np.load(file).astype(np.float16) for i, file in enumerate(train_y_files)])\n",
    "            test_X = np.load(\"../saved_npy_nmt/features/test_X.npy\").astype(np.float16)\n",
    "            test_y = np.load(\"../saved_npy_nmt/features/test_y.npy\").astype(np.float16)\n",
    "            \n",
    "        else:\n",
    "            num_windows = 100\n",
    "            window_size = 200\n",
    "            for i in range(0, len(train_files), 100):\n",
    "                train_X, train_y = build_data(train_files[i:i+100], use_windows=False, window_size=window_size, \n",
    "                                              num_windows=num_windows, dataset = \"nmt\")\n",
    "                np.save(\"../saved_npy_nmt/features/train_X\"+str(i)+\".npy\", train_X.astype(np.float16))\n",
    "                np.save(\"../saved_npy_nmt/features/train_y\"+str(i)+\".npy\", train_y.astype(np.float16))\n",
    "            test_X, test_y = build_data(test_files, use_windows=False, window_size=window_size, \n",
    "                                        num_windows=num_windows, dataset = \"nmt\")\n",
    "            np.save(\"../saved_npy_nmt/features/test_X.npy\", test_X.astype(np.float16))\n",
    "            np.save(\"../saved_npy_nmt/features/test_y.npy\", test_y.astype(np.float16))\n",
    "            clear_output()\n",
    "    \n",
    "            train_X_files = [\"../saved_npy_nmt/features/train_X\"+str(i)+\".npy\" for i in range(0, len(train_files), 100)]\n",
    "            train_y_files = [\"../saved_npy_nmt/features/train_y\"+str(i)+\".npy\" for i in range(0, len(train_files), 100)]\n",
    "            train_X = np.vstack([np.load(file) for file in train_X_files])\n",
    "            train_y = np.vstack([np.load(file) for file in train_y_files])\n",
    "            test_X = np.load(\"../saved_npy_nmt/features/test_X.npy\")\n",
    "            test_y = np.load(\"../saved_npy_nmt/features/test_y.npy\")\n",
    "\n",
    "        np.save(\"../saved_npy_nmt/features/train_X.npy\", train_X)\n",
    "        np.save(\"../saved_npy_nmt/features/train_y.npy\", train_y)\n",
    "        np.save(\"../saved_npy_nmt/features/test_y.npy\", test_y)\n",
    "        np.save(\"../saved_npy_nmt/features/test_X.npy\", test_X)\n",
    "        print(\"make features\")\n",
    "        _ , train_graphs, _, _ , test_graphs, _ = train_test(train_X=train_X, \n",
    "                                                             test_X=test_X, \n",
    "                                                             train_y=train_y, \n",
    "                                                             test_y=test_y, \n",
    "                                                             method=conn)\n",
    "        \n",
    "        np.save(\"../saved_npy_nmt/features/train_X.npy\", train_X)\n",
    "        np.save(\"../saved_npy_nmt/features/train_y.npy\", train_y)\n",
    "        np.save(\"../saved_npy_nmt/features/train_graphs_\"+conn+\".npy\", train_graphs)\n",
    "        np.save(\"../saved_npy_nmt/features/test_y.npy\", test_y)\n",
    "        np.save(\"../saved_npy_nmt/features/test_X.npy\", test_X)\n",
    "        np.save(\"../saved_npy_nmt/features/test_graphs_\"+conn+\".npy\", test_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f01a9fe-b2cc-48e6-9ce0-287f45b92eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 95)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abnormals = 0\n",
    "normals = 0\n",
    "for file in test_files:\n",
    "    if \"abnormal\" in file:\n",
    "        abnormals+=1\n",
    "    else:\n",
    "        normals+=1\n",
    "\n",
    "abnormals, normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e3c3a-85a2-4e91-8654-0cd5d4e3f671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
